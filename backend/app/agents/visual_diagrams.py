"""
Visual Diagram Generator for COMP 237 AI Tutoring

Generates visual representations of AI/ML concepts using:
1. ASCII art diagrams for terminal/text display
2. Mermaid.js syntax for rich frontend rendering

These visuals help students understand abstract concepts.
"""

import logging
from typing import Dict, List, Optional

logger = logging.getLogger(__name__)


# ASCII Art Diagrams for Common Concepts
ASCII_DIAGRAMS = {
    "neural_network": """
```
    Input Layer      Hidden Layer      Output Layer
    
       (xâ‚) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â•²      â”‚
               â•²     â–¼
       (xâ‚‚) â”€â”€â”€â”€â”€â”€â”€â”€(hâ‚)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â•±      â”‚            â•²
             â•±       â”‚             â•²
       (xâ‚ƒ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”€â”€â”€â”€â–¶ (Å·)
              â•²      â”‚             â•±
               â•²     â–¼            â•±
       (xâ‚„) â”€â”€â”€â”€â”€â”€â”€â”€(hâ‚‚)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â•±
             â•±
    
    Each connection has a weight (w)
    Each neuron applies: output = activation(Î£ wáµ¢xáµ¢ + b)
```
""",

    "gradient_descent": """
```
    Loss
      â”‚
      â”‚    â•­â”€â•®
      â”‚   â•±   â•²
      â”‚  â•±     â•²        Current
      â”‚ â•±       â•²       Position
      â”‚â•±    â—â”€â”€â”€â”€â•²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Move in direction
      â”‚      â•²    â•²           of steepest descent
      â”‚       â•²    â•²
      â”‚        â•²    â•²
      â”‚         â•²    â˜… Minimum (goal)
      â”‚          â•²
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Parameters (w)
      
    Step size = learning_rate Ã— gradient
    w_new = w_old - Î± Ã— âˆ‚Loss/âˆ‚w
```
""",

    "backpropagation": """
```
    Forward Pass (â†’)              Backward Pass (â†)
    
    Input â”€â”€â–¶ Hidden â”€â”€â–¶ Output   âˆ‚L/âˆ‚w = âˆ‚L/âˆ‚y Ã— âˆ‚y/âˆ‚w
      x        h          Å·            â†‘
      â”‚        â”‚          â”‚            â”‚
      â–¼        â–¼          â–¼            â”‚
    â”Œâ”€â”€â”€â”    â”Œâ”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”        â”‚
    â”‚ wâ‚â”‚â”€â”€â”€â–¶â”‚ wâ‚‚â”‚â”€â”€â”€â–¶â”‚  Loss â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â””â”€â”€â”€â”˜    â””â”€â”€â”€â”˜    â”‚   L   â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
                    Compute error
                    Propagate back
                    Update weights
    
    Chain Rule: âˆ‚L/âˆ‚wâ‚ = âˆ‚L/âˆ‚Å· Ã— âˆ‚Å·/âˆ‚h Ã— âˆ‚h/âˆ‚wâ‚
```
""",

    "classification_vs_regression": """
```
    CLASSIFICATION                    REGRESSION
    (Discrete output)                 (Continuous output)
    
       â—                                    â—
       â—  â–²                                â—   â”€â”€â”€â”€â”€â”€
      â—â—  â–²â–²â–²                           â—â—  â”€â”€â”€â”€
     â—â—â—  â–²â–²â–²â–²                        â—â—â—â”€â”€â”€â”€ 
    â—â—â—â—  â–²â–²â–²â–²â–²                     â—â—â—â”€â”€â”€â”€
                                   â—â”€â”€â”€â”€
    Classes: A, B, C              Output: 0.0 to âˆ
    
    Examples:                     Examples:
    - Spam detection              - House price
    - Image recognition           - Temperature
    - Disease diagnosis           - Stock price
```
""",

    "decision_tree": """
```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Is it raining? â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                             â”‚
              â–¼                             â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Yes   â”‚                    â”‚   No   â”‚
         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
              â”‚                             â”‚
              â–¼                             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Bring umbrella  â”‚          â”‚ Is it sunny?    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â–¼                       â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚  Yes   â”‚              â”‚   No   â”‚
                         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
                              â–¼                       â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Wear sunglasses â”‚    â”‚ Just go outside â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
""",

    "kmeans_clustering": """
```
    Initial State          After K-Means (K=3)
    
        â—  â—                   â–²  â–²
      â—  â—   â—               â–²  â–²   â–²
        â—  â—                   â–²  â–²
                   â”€â”€â”€â”€â”€â”€â–¶
      â—    â—                 â—    â—
        â—   â—                  â—   â—
      â—                      â—
                    
          â—  â—                   â–   â– 
        â—   â—                  â–    â– 
                    
    Random points          Grouped by nearest centroid
                           (â—, â–², â–  = different clusters)
    
    Algorithm: 1. Pick K random centroids
               2. Assign points to nearest centroid
               3. Move centroids to cluster mean
               4. Repeat until converged
```
""",

    "confusion_matrix": """
```
                      Predicted
                   Positive  Negative
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    Actual   Pos  â”‚   TP    â”‚   FN    â”‚  â† Recall = TP/(TP+FN)
    Class         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
             Neg  â”‚   FP    â”‚   TN    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†‘
              Precision = TP/(TP+FP)
    
    Accuracy = (TP + TN) / Total
    F1 Score = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
    
    TP = True Positive   (Correct positive prediction)
    TN = True Negative   (Correct negative prediction)
    FP = False Positive  (Incorrect positive - Type I Error)
    FN = False Negative  (Incorrect negative - Type II Error)
```
""",

    "overfitting": """
```
    Training Data (â—)        Underfitting    Good Fit    Overfitting
    
    â—     â—                    â”€â”€â”€â”€â”€â”€â”€â”€      â•­â”€â”€â”€â”€â”€â”€â•®    â•­â•® â•­â•® â•­â•®
      â—       â—               /              â”‚      â”‚   â•±  â•²â•±  â•²â•±  â•²
        â— â—                  â”€â”€â”€â”€â”€â”€â”€â”€        â•°â”€â”€â”€â”€â”€â”€â•¯  â•±            â•²
           â—  â—                                       
                            High Bias       Balanced   High Variance
                            Low Variance               Low Bias
    
    Test Error:              High            Low        High
    Training Error:          High            Low        Very Low
    
    Solution: Regularization, more data, simpler model
```
""",

    "activation_functions": """
```
    Sigmoid                 ReLU                    Tanh
    
    1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®       â”‚                  1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
                   â”‚       â”‚   â•±              â”‚           â”‚
    0.5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”‚       â”‚  â•±               0 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—
                   â”‚       â”‚ â•±                â”‚           â”‚
    0 â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚â•±                -1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
           x                    x                   x
    
    Ïƒ(x) = 1/(1+eâ»Ë£)      max(0, x)          (eË£ - eâ»Ë£)/(eË£ + eâ»Ë£)
    Range: (0, 1)         Range: [0, âˆ)      Range: (-1, 1)
    Use: Output layer     Use: Hidden        Use: Hidden layers
         (probability)    layers (default)   (centered)
```
""",

    "train_test_split": """
```
    Full Dataset (100%)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ â— â— â— â— â— â— â— â— â— â— â— â— â— â— â— â— â— â— â— â— â— â— â— â— â— â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼ Random Split
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Training Set (70-80%)          â”‚ â”‚ Test Set      â”‚
    â”‚ â— â— â— â— â— â— â— â— â— â— â— â— â— â— â—  â”‚ â”‚ (20-30%)      â”‚
    â”‚                                â”‚ â”‚ â— â— â— â— â— â—   â”‚
    â”‚ Used to LEARN parameters       â”‚ â”‚ Used to       â”‚
    â”‚                                â”‚ â”‚ EVALUATE      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    Never train on test data! (Data Leakage = Cheating)
```
""",
}


# Mermaid.js Diagrams for Frontend Rendering
MERMAID_DIAGRAMS = {
    "neural_network": """
```mermaid
graph LR
    subgraph Input
        x1((xâ‚))
        x2((xâ‚‚))
        x3((xâ‚ƒ))
    end
    subgraph Hidden
        h1((hâ‚))
        h2((hâ‚‚))
    end
    subgraph Output
        y((Å·))
    end
    x1 --> h1
    x1 --> h2
    x2 --> h1
    x2 --> h2
    x3 --> h1
    x3 --> h2
    h1 --> y
    h2 --> y
```
""",

    "gradient_descent": """
```mermaid
flowchart TD
    A[Initialize weights randomly] --> B[Forward pass: compute prediction]
    B --> C[Compute loss/error]
    C --> D[Compute gradient âˆ‚L/âˆ‚w]
    D --> E[Update weights: w = w - Î± Ã— âˆ‚L/âˆ‚w]
    E --> F{Converged?}
    F -->|No| B
    F -->|Yes| G[Done! Optimal weights found]
```
""",

    "decision_tree": """
```mermaid
graph TD
    A{Feature 1 > threshold?} -->|Yes| B{Feature 2 > threshold?}
    A -->|No| C{Feature 3 > threshold?}
    B -->|Yes| D[Class A]
    B -->|No| E[Class B]
    C -->|Yes| F[Class B]
    C -->|No| G[Class C]
```
""",

    "supervised_learning": """
```mermaid
flowchart LR
    subgraph Training
        A[Labeled Data] --> B[Model learns patterns]
        B --> C[Trained Model]
    end
    subgraph Prediction
        D[New Data] --> C
        C --> E[Prediction]
    end
```
""",

    "classification_pipeline": """
```mermaid
flowchart LR
    A[Raw Data] --> B[Preprocessing]
    B --> C[Feature Engineering]
    C --> D[Train/Test Split]
    D --> E[Model Training]
    E --> F[Evaluation]
    F --> G{Good enough?}
    G -->|No| H[Tune hyperparameters]
    H --> E
    G -->|Yes| I[Deploy Model]
```
""",
}


def get_ascii_diagram(concept: str) -> Optional[str]:
    """
    Get ASCII art diagram for a concept.
    
    Args:
        concept: The concept to visualize (e.g., 'neural_network', 'gradient_descent')
        
    Returns:
        ASCII diagram string or None if not available
    """
    return ASCII_DIAGRAMS.get(concept)


def get_mermaid_diagram(concept: str) -> Optional[str]:
    """
    Get Mermaid.js diagram for a concept.
    
    Args:
        concept: The concept to visualize
        
    Returns:
        Mermaid diagram string or None if not available
    """
    return MERMAID_DIAGRAMS.get(concept)


def get_visual_for_concept(concept: str, prefer_mermaid: bool = False) -> Optional[str]:
    """
    Get the best available visual for a concept.
    
    Args:
        concept: The concept to visualize
        prefer_mermaid: If True, prefer Mermaid over ASCII when both available
        
    Returns:
        Visual diagram string or None
    """
    if prefer_mermaid:
        return get_mermaid_diagram(concept) or get_ascii_diagram(concept)
    else:
        return get_ascii_diagram(concept) or get_mermaid_diagram(concept)


def list_available_visuals() -> Dict[str, List[str]]:
    """
    List all available visual diagrams.
    
    Returns:
        Dict with 'ascii' and 'mermaid' keys listing available concepts
    """
    return {
        "ascii": list(ASCII_DIAGRAMS.keys()),
        "mermaid": list(MERMAID_DIAGRAMS.keys()),
    }


# Concept name to diagram key mapping
CONCEPT_TO_DIAGRAM = {
    "neural_networks": "neural_network",
    "neural_network": "neural_network",
    "perceptron": "neural_network",
    "deep_learning": "neural_network",
    "gradient_descent": "gradient_descent",
    "optimization": "gradient_descent",
    "learning_rate": "gradient_descent",
    "backpropagation": "backpropagation",
    "chain_rule": "backpropagation",
    "classification": "classification_vs_regression",
    "regression": "classification_vs_regression",
    "supervised_learning": "supervised_learning",
    "decision_trees": "decision_tree",
    "decision_tree": "decision_tree",
    "clustering": "kmeans_clustering",
    "kmeans": "kmeans_clustering",
    "k_means": "kmeans_clustering",
    "model_evaluation": "confusion_matrix",
    "confusion_matrix": "confusion_matrix",
    "accuracy": "confusion_matrix",
    "precision": "confusion_matrix",
    "recall": "confusion_matrix",
    "overfitting": "overfitting",
    "underfitting": "overfitting",
    "regularization": "overfitting",
    "activation_functions": "activation_functions",
    "sigmoid": "activation_functions",
    "relu": "activation_functions",
    "tanh": "activation_functions",
    "train_test_split": "train_test_split",
    "data_preprocessing": "train_test_split",
}


def get_diagram_for_detected_concept(detected_concept: str) -> Optional[str]:
    """
    Get a diagram based on a detected concept from query.
    
    Args:
        detected_concept: The concept detected from user query
        
    Returns:
        ASCII diagram string or None
    """
    diagram_key = CONCEPT_TO_DIAGRAM.get(detected_concept)
    if diagram_key:
        return get_ascii_diagram(diagram_key)
    return None


def format_diagram_for_response(diagram: str, title: str = "Visual") -> str:
    """
    Format a diagram for embedding in a tutor response.
    """
    return f"\n\nğŸ“Š **{title}:**\n{diagram}"
