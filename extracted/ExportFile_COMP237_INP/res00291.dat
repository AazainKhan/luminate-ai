<?xml version="1.0" encoding="UTF-8"?>
<CONTENT id="_800653_1"><TITLE value="Topic 10.1: Introduction and NLP applications"/><TITLECOLOR
  value="#000000"/><DESCRIPTION
   value=""/><BODY><TEXT>&lt;div data-layout-row="eed666f4-3186-47f9-9b45-36bb42e056b6"&gt;&lt;div data-layout-column="b77daab4-9409-4912-9efa-8c76f755b2c2" data-layout-column-width="12"&gt;&lt;div data-bbid="bbml-editor-id_1a1c24ee-70cd-44fd-8bd9-aef97486f091"&gt;&lt;h5&gt;Topic 10.1: &lt;span style="color: #1c8845"&gt;Introduction and NLP applications&lt;/span&gt;&lt;/h5&gt;&lt;br&gt;&lt;h5&gt;&lt;span style="color: #1c8845"&gt;Introduction&lt;/span&gt;&lt;/h5&gt;&lt;br&gt;&lt;p&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;100,000&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt; years ago humans learnt how to speak&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;. 5,000&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt; years ago humans learnt how to write. Language&amp;nbsp;captures so much of the &lt;/span&gt;&lt;/span&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;intelligent behavior&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt;.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Watch this video then continue reading:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;a href="https://mediasite.centennialcollege.ca/Mediasite/Play/a5986c2451584b9486417243e7a3d5091d" data-bbtype="video" data-bbfile="{&amp;quot;src&amp;quot;:&amp;quot;https://mediasite.centennialcollege.ca/Mediasite/Play/a5986c2451584b9486417243e7a3d5091d&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;https://mediasite.centennialcollege.ca/Mediasite/Play/a5986c2451584b9486417243e7a3d5091d&amp;quot;}"&gt;https://mediasite.centennialcollege.ca/Mediasite/Play/a5986c2451584b9486417243e7a3d5091d&lt;/a&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;Alan Turing based his AI test on &lt;strong&gt;language&lt;/strong&gt;. Because language captures so much of the &lt;strong&gt;intelligent behavior&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;&lt;span style="color: #1c8845"&gt;&lt;strong&gt;Speaker or writer&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #1c8845"&gt;: &lt;/span&gt;has a goal of communicating knowledge.&lt;/p&gt;&lt;p&gt;&lt;span style="color: #1c8845"&gt;&lt;strong&gt;Plans&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #1c8845"&gt;: &lt;/span&gt;Some language that represents the knowledge and acts.&lt;/p&gt;&lt;p&gt;&lt;span style="color: #1c8845"&gt;&lt;strong&gt;Listener&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #1c8845"&gt;: &lt;/span&gt;Perceives knowledge and infers the intend meaning.&lt;/p&gt;&lt;p&gt;In order to &lt;span style="color: #1c8845"&gt;&lt;strong&gt;pass&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #1c8845"&gt; &lt;/span&gt;the turning test the computer would need to possess the following capabilities, illustrated in the diagram below:&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693175_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Turing test&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M10_allen_test.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M10_allen_test.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;As you can notice from the above diagram, NLP is one of the main capabilities required to enable the computer (machine) to communicate sucessfully.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Natural Language Processing (NLP):&lt;/strong&gt; Is broadly defined as the automatic manipulation of natural language, like speech and text, by&lt;span style="color: #000000"&gt;&lt;strong&gt; software&lt;/strong&gt;&lt;/span&gt;. The study of natural language processing has been around for more than 50 years and grew out of the field of&lt;span style="color: #000000"&gt;&lt;strong&gt; linguistics&lt;/strong&gt;&lt;/span&gt; with the rise of computers.&lt;/p&gt;&lt;p&gt;The main reasons for why NLP is important are as follows:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;To Communicate with humans.&lt;/li&gt;&lt;li&gt;To learn from the digital knowledge for example,&amp;nbsp;Wikipedia 30 million pages.&lt;/li&gt;&lt;li&gt;To advance the scientific understanding&amp;nbsp;of language (using tools of AI).&lt;/li&gt;&lt;/ol&gt;&lt;h5&gt;&lt;span style="color: #1c8845"&gt;Application areas of NLP&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;As shown in the below figure the main applications of AI are:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Speech recognition&lt;/li&gt;&lt;li&gt;Information extraction&lt;/li&gt;&lt;li&gt;Text to speech&lt;/li&gt;&lt;li&gt;Machine translation&lt;/li&gt;&lt;li&gt;Information retrieval&lt;/li&gt;&lt;li&gt;Question Answering&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693176_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Application areas of NLP&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M10_app_area.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;,&amp;quot;width&amp;quot;:516.9375,&amp;quot;height&amp;quot;:347.8923836078517}"&gt;M10_app_area.png&lt;/a&gt;&lt;/p&gt;&lt;h5&gt;Speech recognition&lt;/h5&gt;&lt;p&gt;Speech recognition is the task of transforming spoken sound into text. (current systems&amp;nbsp;have an error rate of about 3% to 5%).&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693177_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Imange of a Mic : Ref: Pixbay&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M10_speech_recognition_mic.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M10_speech_recognition_mic.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Top systems use &lt;span style="color: #000000"&gt;recurrent neural networks&lt;/span&gt; and hidden &lt;span style="color: #000000"&gt;Markov chains&lt;/span&gt;.&lt;/p&gt;&lt;p&gt;The introduction of &lt;span style="color: #000000"&gt;deep neural networks&lt;/span&gt; for speech in 2011 improvement of 30% in the error rate.&lt;/p&gt;&lt;p&gt;The process involves 2 stages as follows:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;Waveforms&amp;nbsp;→&amp;nbsp;&amp;nbsp;Phonemes&amp;nbsp;→ Words&amp;nbsp;&amp;nbsp;&amp;nbsp;→&amp;nbsp;Sentences&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Waveforms (analog acoustic signals) need to be transformed&amp;nbsp;into digital signals and then into numeric frames with features, as per the below figure:&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693178_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Waveform ref: https://commons.wikimedia.org/wiki/File:Andrea_Electronics_PureAudio_Speech_Development_Kit_(39763899664).png&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M10_M10_speech_recognition_wave.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M10_M10_speech_recognition_wave.png&lt;/a&gt; &lt;span style="color: #000000"&gt;&lt;span style="font-size: 3rem;"&gt;→&amp;nbsp;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693179_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;waveform to feature &amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M10_M10_speech_recognition_analog_to digital.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M10_M10_speech_recognition_analog_to digital.png&lt;/a&gt;&lt;/p&gt;&lt;h5&gt;Text to speech&lt;/h5&gt;&lt;p&gt;Text to speech is the &lt;span style="color: #000000"&gt;inverse task&lt;/span&gt; of speech recognition i.e. going from text to sound, this is called &lt;span style="color: #000000"&gt;synthesis&lt;/span&gt;.&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693180_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Text to Speech Ref:https://pixabay.com/illustrations/speech-icon-voice-talking-audio-2797263/ Ref: https://pixabay.com/vectors/text-balloons-message-speech-35398/&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M10_text_to_speech.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M10_text_to_speech.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The introduction of deep recurrent neural networks&amp;nbsp;led to a large improvement with about 2/3 listeners stating that the Wave Net system sounded more natural.&lt;/p&gt;&lt;p&gt;Synthesizing has many different application areas:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Male versus Female&lt;/li&gt;&lt;li&gt;Regional dialects&lt;/li&gt;&lt;li&gt;Celebrity voices&lt;/li&gt;&lt;/ol&gt;&lt;h5&gt;Machine translation&lt;/h5&gt;&lt;p&gt;Machine translation is the task of transforming text from one language to another.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693181_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Machine language translation. Ref: https://commons.wikimedia.org/wiki/File:%C3%86toms_-_Translation.svg&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M10_machine_translation.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M10_machine_translation.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Originally machine translation used n-grams models. They worked we but had limitation. For example:&lt;/p&gt;&lt;p&gt;From English to French the phrase &lt;span style="color: #000000"&gt;“Black cat&lt;/span&gt;” translates to &lt;span style="color: #000000"&gt;“Chat noir”.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;But the system could not learn the rule that&amp;nbsp;adjectives generally come before noun in English and after noun in French.&lt;/p&gt;&lt;p&gt;Recurrent neural sequence to sequence models (2015) got around the problem.&lt;/p&gt;&lt;h5&gt;Information extraction&lt;/h5&gt;&lt;p&gt;Information extraction is the task of &lt;span style="color: #000000"&gt;acquiring knowledge&lt;/span&gt; by skimming a text and looking for&lt;span style="color: #000000"&gt; occurrences&lt;/span&gt; of particular classes of objects and for relationships among them.&lt;/p&gt;&lt;p&gt;Examples:&lt;/p&gt;&lt;p&gt;1- Extract instances of addresses (city, state, and zip code)&amp;nbsp;from web pages.&lt;/p&gt;&lt;p&gt;2- Extract instances of storm from weather reports.&lt;/p&gt;&lt;p&gt;Originally Markov models and rule based learning systems were used in Text runner an NELL(Never ending language learning).&lt;/p&gt;&lt;p&gt;More recent: Recurrent neural networks.&lt;/p&gt;&lt;p&gt;Check out the following link to learn about the NELL project:&lt;/p&gt;&lt;p&gt;&lt;a href="http://rtw.ml.cmu.edu/rtw/"&gt;http://rtw.ml.cmu.edu/rtw/&lt;/a&gt;&lt;/p&gt;&lt;h5&gt;Information retrieval&lt;/h5&gt;&lt;p&gt;Information retrieval is the task of &lt;span style="color: #000000"&gt;finding documents&lt;/span&gt; that are&lt;span style="color: #000000"&gt; relevant&lt;/span&gt; and important for a given query. For example Google and Baidu search engines.&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693182_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Google and Bauidu image logos Ref:https://www.google.com/search?q=baidu%20search%20engine%20icon&amp;amp;tbm=isch&amp;amp;hl=en&amp;amp;hl=en&amp;amp;safe=active&amp;amp;safe=active&amp;amp;tbs&amp;amp;rlz=1C1GCEA_enCA850CA850&amp;amp;sa=X&amp;amp;ved=0CAEQpwVqFwoTCLDInYO&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M10_google_badui.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;,&amp;quot;width&amp;quot;:720.5479452054794,&amp;quot;height&amp;quot;:199.99999999999997}"&gt;M10_google_badui.png&lt;/a&gt;&lt;/p&gt;&lt;h5&gt;Question Answering&lt;/h5&gt;&lt;p&gt;Question Answering is the task of constructing queries as questions such as "Who found the U.S. coast guard?" and the response is not a ranked list of documents but rather an actual answer for example: "Alexander Hamilton".&lt;/p&gt;&lt;p&gt;Such systems have used the web information as of 2001 to radically increase the breadth of the coverage.&lt;/p&gt;&lt;p&gt;Check out the &lt;span style="color: #000000"&gt;&lt;strong&gt;AI2 ARC&lt;/strong&gt;&lt;/span&gt;&amp;nbsp;Challenge at the following link:&lt;/p&gt;&lt;p&gt;&lt;a href="https://allenai.org/data/arc"&gt;https://allenai.org/data/arc&lt;/a&gt;&lt;/p&gt;&lt;h4&gt;&lt;span style="color: #1c8845"&gt;Language models&lt;/span&gt;&lt;/h4&gt;&lt;br&gt;&lt;p&gt;Natural languages, such as English and Chinese cannot be neatly characterized for the following reasons:&lt;/p&gt;&lt;ol&gt;&lt;li style="font-size: 1.125rem;
          padding-left: 1.487rem;"&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;Language judgments vary&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt; from person to person and time to time.&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li style="font-size: 1.125rem;
          padding-left: 1.487rem;"&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt;Natural language is &lt;/span&gt;&lt;/span&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;ambiguous&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt;:&amp;nbsp;For example “He saw her duck” might mean : either she owns a waterfowl (actual bird)&amp;nbsp;Or She made downward evasive move&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li style="font-size: 1.125rem;
          padding-left: 1.487rem;"&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt;Natural language is &lt;/span&gt;&lt;/span&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;vague:&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt; For example: “That’s great” doesn't specify precisely how great it is nor what it is.&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Based on this, if we cannot make a &lt;span style="color: #000000"&gt;definitive Boolean&lt;/span&gt; distinction between grammatical and ungrammatical strings we can at least say how&amp;nbsp;&lt;span style="color: #000000"&gt;&lt;strong&gt;likely&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 0.875rem;"&gt;and &lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 0.875rem;"&gt;&lt;strong&gt;unlikely&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size: 0.875rem;"&gt; each one is.&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt;Language model: A probability distribution describing the likelihood of any string.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 0.875rem;"&gt;Some of the famous language models are:&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol&gt;&lt;li style="font-size: 0.875rem;
          padding-left: 1.319rem;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 0.875rem;"&gt;Bag of words&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li style="font-size: 0.875rem;
          padding-left: 1.319rem;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 0.875rem;"&gt;N-grams&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 0.875rem;"&gt;&lt;strong&gt;Probability theory&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt; &lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 0.875rem;"&gt;is in the heart of algorithms used for NLP and one of the main algorithms is Naieve Bayes which builds on Bayes rule that we will discuss in the next topic.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693183_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Language models and probability&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M10_probability.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M10_probability.png&lt;/a&gt;&lt;/p&gt;&lt;h5&gt;References&lt;/h5&gt;&lt;ol&gt;&lt;li&gt;Chapter 23 Artificial intelligence a modern approach by Stuart J. Russell and Peter Norvig.&lt;/li&gt;&lt;li&gt;Chapter 5&amp;amp;15 &lt;a href="https://learning.oreilly.com/library/view/artificial-intelligence-with/9781786464392/"&gt;Artificial Intelligence with Python&lt;/a&gt;&amp;nbsp;second edition by Prateek Joshi&lt;/li&gt;&lt;li&gt;&lt;a href="https://machinelearningmastery.com/natural-language-processing/"&gt;https://machinelearningmastery.com/natural-language-processing&lt;/a&gt;&lt;/li&gt;&lt;li&gt;An overview of the Natural Language Toolkit, Steven Bird, Ewan Klein, Edward Loper nltk.org&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.geeksforgeeks.org/removing-stop-words-nltk-python/"&gt;https://www.geeksforgeeks.org/removing-stop-words-nltk-python/&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://rtw.ml.cmu.edu/rtw/"&gt;http://rtw.ml.cmu.edu/rtw/&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://allenai.org/data/arc"&gt;https://allenai.org/data/arc&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</TEXT><TYPE
   value="H"/></BODY><DATES><CREATED value="2024-10-04 18:31:47 EDT"/><UPDATED value="2024-11-14 15:56:35 EST"/><START
   value=""/><END value=""/></DATES><FLAGS><ISAVAILABLE value="true"/><ISFROMCARTRIDGE value="false"/><ISFOLDER
   value="false"/><ISDESCRIBED value="false"/><ISTRACKED value="true"/><ISLESSON value="false"/><ISSEQUENTIAL
   value="false"/><ALLOWGUESTS value="true"/><ALLOWOBSERVERS value="true"/><LAUNCHINNEWWINDOW
   value="false"/><ISREVIEWABLE value="false"/><ISGROUPCONTENT value="false"/><ISSAMPLECONTENT
   value="false"/><PARTIALLYVISIBLE value="false"/><HASTHUMBNAIL value="false"/></FLAGS><CONTENTHANDLER
  value="resource/x-bb-document"/><RENDERTYPE value="REGULAR"/><FOLDERTYPE value=""/><URL value=""/><VIEWMODE
  value="TEXT_ICON_ONLY"/><OFFLINENAME value=""/><OFFLINEPATH value=""/><LINKREF value=""/><PARENTID
  value="_800536_1"/><REVIEWABLEREASON value="NONE"/><VERSION value="3"/><THUMBNAILALT value=""/><AISTATE
  value="No"/><AIACCEPTINGUSER value=""/><EXTENDEDDATA/><FILES/></CONTENT>
