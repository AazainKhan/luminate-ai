<?xml version="1.0" encoding="UTF-8"?>
<CONTENT id="_800664_1"><TITLE value="Topic 2.2: Environments"/><TITLECOLOR value="#000000"/><DESCRIPTION
   value=""/><BODY><TEXT>&lt;div data-layout-row="25ac52f8-ac77-4049-868e-c944ebdcce3a"&gt;&lt;div data-layout-column="d5b75a9d-6f70-41b1-b95f-66dea380ae48" data-layout-column-width="12"&gt;&lt;div data-bbid="bbml-editor-id_93b5dcca-abcc-476f-b760-fcb1516fe27c"&gt;&lt;h4&gt;Topic 2.2: Environments&lt;/h4&gt;&lt;br&gt;&lt;h5&gt;&lt;span style="color: #1c8845"&gt;The nature of environments&lt;/span&gt;&lt;/h5&gt;&lt;br&gt;&lt;p&gt;In this topic we will explain more on the task environment, as it is very important to understand the properties of the environment in order to be able to design intelligent and rational agents.&lt;/p&gt;&lt;h6&gt;Watch this video, then continue reading the topic material&lt;/h6&gt;&lt;p style="text-align: center;"&gt;&lt;a href="https://mediasite.centennialcollege.ca/Mediasite/Play/30ced1496ef84bf28ea2085c688c6ea51d" data-bbtype="video" data-bbfile="{&amp;quot;src&amp;quot;:&amp;quot;https://mediasite.centennialcollege.ca/Mediasite/Play/30ced1496ef84bf28ea2085c688c6ea51d&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;https://mediasite.centennialcollege.ca/Mediasite/Play/30ced1496ef84bf28ea2085c688c6ea51d&amp;quot;}"&gt;https://mediasite.centennialcollege.ca/Mediasite/Play/30ced1496ef84bf28ea2085c688c6ea51d&lt;/a&gt;&lt;/p&gt;&lt;br&gt;&lt;h6&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-family: Comic Sans MS;"&gt;&lt;span style="font-size: 1.125rem;"&gt;The task environment&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h6&gt;&lt;br&gt;&lt;p&gt;The Task environment includes:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;the performance measure&lt;/li&gt;&lt;li&gt;the environment&lt;/li&gt;&lt;li&gt;the agent’s actuators and sensors&lt;/li&gt;&lt;/ol&gt;&lt;br&gt;&lt;h6&gt;This is referred to as &lt;span style="color: #000000"&gt;&lt;strong&gt;PEAS&lt;/strong&gt;&lt;/span&gt;:&lt;/h6&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt;PEAS (Performance, Environment, Actuators, Sensors)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left;"&gt;Let us take an example of an autonomous taxi driver, have a look at the figure below and notice the PEAS environment, this will give you a good idea about each component of the PEAS environment for this type of problem:&lt;/p&gt;&lt;br&gt;&lt;p style="text-align: left;"&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1692611_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;autonomous taxi driver&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M2_taxi.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;,&amp;quot;width&amp;quot;:807.2750244140625,&amp;quot;height&amp;quot;:418.58124065396765}"&gt;M2_taxi.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Also examine the below table to learn more about other type of agent problems and the PEAS task environment for each type of problem:&lt;/p&gt;&lt;p style="text-align: left;"&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1692612_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;more examples of PEAS&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M2_more_environments.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M2_more_environments.png&lt;/a&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;It is important to abstract each new problem and to create the correct artifacts.&lt;/p&gt;&lt;h5 style="text-align: left;"&gt;&lt;span style="color: #1c8845"&gt;Task environment properties&amp;nbsp;&lt;/span&gt;&lt;/h5&gt;&lt;br&gt;&lt;p&gt;The range of task environments that might arise in AI is vast. However, we can identify a fairly small number of dimensions (properties) along which task environments can be &lt;span style="color: #000000"&gt;&lt;strong&gt;categorized&lt;/strong&gt;&lt;/span&gt;.&lt;/p&gt;&lt;p&gt;These properties determine to a large extent the &lt;span style="color: #000000"&gt;&lt;strong&gt;appropriate agent design&lt;/strong&gt;&lt;/span&gt;.&lt;/p&gt;&lt;p&gt;The figure below summarizes these dimension (properties) that all task environments share:&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1692613_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;propertieis / dimenssions of PEAS task environments &amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M2_types_of enviromrnts.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M2_types_of enviromrnts.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Let's look more in depth at these dimensions:&lt;/p&gt;&lt;h6&gt;&lt;span style="font-size: 1.125rem;"&gt;1. Fully observable vs. partially observable&lt;/span&gt;&lt;/h6&gt;&lt;br&gt;&lt;p&gt;If an agent’s sensors give it access to the complete state of the environment at each point in time, then we say that the task environment is fully observable.&lt;/p&gt;&lt;h6&gt;Examples:&lt;/h6&gt;&lt;ol&gt;&lt;li&gt;A vacuum agent with only a local dirt sensor cannot tell whether there is dirt in other squares.&lt;/li&gt;&lt;li&gt;An automated taxi cannot see what other drivers are thinking.&lt;/li&gt;&lt;/ol&gt;&lt;h6&gt;&lt;span style="font-size: 1.125rem;"&gt;2. Single agent vs. multi-agent&lt;/span&gt;&lt;/h6&gt;&lt;br&gt;&lt;h6&gt;Examples:&lt;/h6&gt;&lt;ol&gt;&lt;li&gt;An agent solving a crossword puzzle by itself is clearly in a single-agent environment.&lt;/li&gt;&lt;li&gt;An agent playing chess is in a two agent environment, is a multi-agent.&lt;/li&gt;&lt;/ol&gt;&lt;h6&gt;&lt;span style="font-size: 1.125rem;"&gt;3. Deterministic vs. stochastic&lt;/span&gt;&lt;/h6&gt;&lt;br&gt;&lt;p&gt;If the next state of the environment is completely determined by the current state and the action executed by the agent, then we say the environment is deterministic; otherwise, it is stochastic.&lt;/p&gt;&lt;h6&gt;Example:&lt;/h6&gt;&lt;p&gt;Taxi driving is clearly stochastic in this sense, because one can never predict the behavior of traffic exactly.&lt;/p&gt;&lt;h6&gt;&lt;span style="font-size: 1.125rem;"&gt;4. Episodic vs. sequential&lt;/span&gt;&lt;/h6&gt;&lt;br&gt;&lt;p&gt;In an episodic task environment, the agent’s experience is divided into atomic episodes. In each episode the agent receives a precept and then performs a single action. Crucially, the next episode does not depend on the actions taken in previous episodes.&lt;/p&gt;&lt;h6&gt;Example:&lt;/h6&gt;&lt;p&gt;An agent that has to spot defective parts on an assembly line bases each decision on the current part, regardless of previous decisions.&lt;/p&gt;&lt;h6&gt;&lt;span style="font-size: 1.125rem;"&gt;5. Static vs. dynamic&lt;/span&gt;&lt;/h6&gt;&lt;br&gt;&lt;p&gt;If the environment can change while an agent is deliberating, then we say the environment is dynamic for that agent; otherwise, it is static.&lt;/p&gt;&lt;p&gt;If the environment itself does not change with the passage of time but the agent’s performance score does, then we say the environment is &lt;em&gt;semi-dynamic&lt;/em&gt;.&lt;/p&gt;&lt;h6&gt;Examples:&lt;/h6&gt;&lt;ol&gt;&lt;li&gt;Crossword puzzles are static.&lt;/li&gt;&lt;li&gt;Taxi driving is clearly dynamic.&lt;/li&gt;&lt;li&gt;Chess, when played with a clock, is semi-dynamic.&lt;/li&gt;&lt;/ol&gt;&lt;h6&gt;&lt;span style="font-size: 1.125rem;"&gt;6. Discrete vs. continuous&lt;/span&gt;&lt;/h6&gt;&lt;br&gt;&lt;p&gt;The discrete/continuous distinction applies to the state of the environment, to the way time is handled, and to the precepts and actions of the agent.&lt;/p&gt;&lt;h6&gt;Examples:&lt;/h6&gt;&lt;ol&gt;&lt;li&gt;The chess environment has a finite number of distinct states (excluding the clock). Chess also has a discrete set of precepts and actions.&lt;/li&gt;&lt;li&gt;Taxi driving is a continuous-state and continuous-time problem: the speed and location of the taxi and of the other vehicles sweep through a range of continuous values and do so smoothly over time.&lt;/li&gt;&lt;/ol&gt;&lt;h6&gt;&lt;span style="font-size: 1.125rem;"&gt;7. Known vs. unknown&lt;/span&gt;&lt;/h6&gt;&lt;br&gt;&lt;p&gt;Strictly speaking, this distinction refers not to the environment itself but to the agent’s (or designer’s) state of knowledge about the “laws of physics” of the environment.&lt;/p&gt;&lt;h6&gt;Examples:&lt;/h6&gt;&lt;ol&gt;&lt;li&gt;In solitaire card games, the rules are known but the agent is unable to see the cards that have not yet been turned over.&lt;/li&gt;&lt;li&gt;In a new video game, the screen may show the entire game state but the agent doesn’t know what the buttons do until the agent tries them.&lt;/li&gt;&lt;/ol&gt;&lt;br&gt;&lt;br&gt;&lt;h5&gt;References&lt;/h5&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Artificial intelligence a modern approach&lt;/strong&gt; by Stuart J. Russell and Peter Norvig, Chapter 2&lt;/li&gt;&lt;li&gt;UC Berkeley CS188 Intro to AI&lt;a href="http://ai.berkeley.edu/home.html"&gt;http://ai.berkeley.edu/home.html&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</TEXT><TYPE
   value="H"/></BODY><DATES><CREATED value="2024-10-04 18:31:42 EDT"/><UPDATED value="2024-11-11 18:32:00 EST"/><START
   value=""/><END value=""/></DATES><FLAGS><ISAVAILABLE value="true"/><ISFROMCARTRIDGE value="false"/><ISFOLDER
   value="false"/><ISDESCRIBED value="false"/><ISTRACKED value="true"/><ISLESSON value="false"/><ISSEQUENTIAL
   value="false"/><ALLOWGUESTS value="true"/><ALLOWOBSERVERS value="true"/><LAUNCHINNEWWINDOW
   value="false"/><ISREVIEWABLE value="false"/><ISGROUPCONTENT value="false"/><ISSAMPLECONTENT
   value="false"/><PARTIALLYVISIBLE value="false"/><HASTHUMBNAIL value="false"/></FLAGS><CONTENTHANDLER
  value="resource/x-bb-document"/><RENDERTYPE value="REGULAR"/><FOLDERTYPE value=""/><URL value=""/><VIEWMODE
  value="TEXT_ICON_ONLY"/><OFFLINENAME value=""/><OFFLINEPATH value=""/><LINKREF value=""/><PARENTID
  value="_800492_1"/><REVIEWABLEREASON value="NONE"/><VERSION value="3"/><THUMBNAILALT value=""/><AISTATE
  value="No"/><AIACCEPTINGUSER value=""/><EXTENDEDDATA/><FILES/></CONTENT>
