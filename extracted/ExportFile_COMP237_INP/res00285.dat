<?xml version="1.0" encoding="UTF-8"?>
<CONTENT id="_800647_1"><TITLE value="Topic 8.1: Introduction to Artificial Neural Networks"/><TITLECOLOR
  value="#000000"/><DESCRIPTION
   value=""/><BODY><TEXT>&lt;div data-layout-row="0a79d06e-9428-47d3-b355-b76597d40fc6"&gt;&lt;div data-layout-column="fb8c7ef8-8532-48cb-9202-75a841a44d10" data-layout-column-width="12"&gt;&lt;div data-bbid="bbml-editor-id_470e65ed-4bc3-4c90-a1d7-dfa4fc685d4f"&gt;&lt;h4&gt;Topic 8.1: Introduction to Artificial Neural Networks (ANN)&lt;/h4&gt;&lt;br&gt;&lt;h5&gt;&lt;span style="color: #1c8845"&gt;Introduction to ANN&lt;/span&gt;&lt;/h5&gt;&lt;br&gt;&lt;p&gt;Artificial neural networks are biologically inspired computational networks. Over the last decade massive advancements have happened in this field and many applications incorporate them.&lt;/p&gt;&lt;p&gt;Watch this video then continue reading:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;a href="https://mediasite.centennialcollege.ca/Mediasite/Play/d1cc64ac71b24dcba63878dea83545b41d" data-bbtype="video" data-bbfile="{&amp;quot;src&amp;quot;:&amp;quot;https://mediasite.centennialcollege.ca/Mediasite/Play/d1cc64ac71b24dcba63878dea83545b41d&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;https://mediasite.centennialcollege.ca/Mediasite/Play/d1cc64ac71b24dcba63878dea83545b41d&amp;quot;}"&gt;https://mediasite.centennialcollege.ca/Mediasite/Play/d1cc64ac71b24dcba63878dea83545b41d&lt;/a&gt;&lt;/p&gt;&lt;br&gt;&lt;h5&gt;History&lt;/h5&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693111_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Books&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M8_history.jpg&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/jpeg&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M8_history.jpg&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Many people think that artificial neural networks are new but that us far from true the origins date back to 1943, take a few minutes to go through the key milestones:&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;1943:&lt;/strong&gt;&lt;/span&gt; &lt;strong&gt;&lt;span style="text-decoration:underline;"&gt;McCulloch and Pitts&lt;/span&gt;&lt;/strong&gt; modeled the neural networks based on their understanding of neurology. Neurons embed simple logic functions:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;a or b&lt;/li&gt;&lt;li&gt;a and b&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;1950s:&lt;/strong&gt;&lt;/span&gt; &lt;strong&gt;&lt;span style="text-decoration:underline;"&gt;Farley and Clark&lt;/span&gt;&lt;/strong&gt;&amp;nbsp;from the&amp;nbsp;IBM group tried to model biological behavior, they consulted neuro-scientists at McGill, whenever stuck.&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;1958:&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span style="text-decoration:underline;"&gt;Rosenblatt&lt;/span&gt;&lt;/strong&gt;&amp;nbsp;Introduced the concept of the Perceptron Association units A1, A2, … extract features from user input, output is weighted and an associated function fires if weighted sum of input exceeds a threshold.&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693112_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Original Perceptron&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M8_original perceptron.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M8_original perceptron.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;But&amp;nbsp;&lt;strong&gt;&lt;span style="text-decoration:underline;"&gt;Minsky and Papert&amp;nbsp;&lt;/span&gt;&lt;/strong&gt;showed that a single layer perceptron &lt;span style="color: #000000"&gt;cannot learn the XOR&lt;/span&gt; of two binary inputs, this lead to &lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;span style="text-decoration:underline;"&gt;loss of interest (and funding&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="text-decoration:underline;"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;span style="text-decoration:underline;"&gt; &lt;/span&gt;in the field.&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;1974 – mid 1980 :&lt;/strong&gt;&lt;/span&gt; &lt;strong&gt;&lt;span style="text-decoration:underline;"&gt;Werbos&lt;/span&gt;&lt;/strong&gt;&lt;span style="text-decoration:underline;"&gt; &lt;/span&gt;introduces Back-propagation learning method&amp;nbsp;and better learning rule for generic three layer networks this&amp;nbsp;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;span style="text-decoration:underline;"&gt;regenerates interest&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="text-decoration:underline;"&gt; &lt;/span&gt;&lt;/span&gt;in the 1980s&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;1986:&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span style="text-decoration:underline;"&gt; (Rumelhart and Mclelland)&lt;/span&gt;&lt;/strong&gt; Parallel distributed processing&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;1980 -2010:&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt; &lt;/span&gt;Geoffrey Hinton re-surged the neural networks against symbolic models and logistic&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;1990:&lt;/strong&gt;&lt;/span&gt; Successful applications in medicine, marketing, risk management, …&amp;nbsp;()&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;2011:&lt;/strong&gt;&lt;/span&gt; Deep Learning – Convolutional neural networks&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;2012:&lt;/strong&gt;&lt;/span&gt; ImageNet competition.&lt;/p&gt;&lt;h5&gt;&lt;span style="color: #1c8845"&gt;Nero science - the biological nervous systems&lt;/span&gt;&lt;/h5&gt;&lt;br&gt;&lt;p&gt;Information processing paradigm inspired by biological nervous systems, have a look at the below figure:&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693113_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Nero science versus ANN&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M8_neuro.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;,&amp;quot;width&amp;quot;:954.4000244140625,&amp;quot;height&amp;quot;:264.90735591610314}"&gt;M8_neuro.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Neuron scientists confirm the activities of the biological nervous systems, as follows:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Neuron collects signals from dendrites&lt;/li&gt;&lt;li&gt;Sends out spikes of electrical activity through an axon, which splits into thousands of branches.&lt;/li&gt;&lt;li&gt;At end of each branch, a synapses converts activity into either &lt;strong&gt;exciting or inhibiting&lt;/strong&gt; activity of a dendrite at another neuron.&lt;/li&gt;&lt;li&gt;Neuron &lt;strong&gt;fires &lt;/strong&gt;when exciting activity surpasses inhibitory activity&lt;/li&gt;&lt;li&gt;Learning changes the effectiveness of the synapses.&lt;/li&gt;&lt;/ol&gt;&lt;h5&gt;&lt;span style="color: #1c8845"&gt;Artificial Neural network structure&lt;/span&gt;&lt;/h5&gt;&lt;br&gt;&lt;p&gt;An ANN contains many neurons (units) that connect to one another.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Each individual neuron is a simple construct:&lt;/strong&gt; it accepts several numerical input values and outputs a single numerical value, which may in turn be transmitted to several other neurons.&lt;/p&gt;&lt;p&gt;The following figure illustrates is a simple, conceptual example of a neuron:&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693114_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;conceptual example of a neuron&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M8_neuron.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M8_neuron.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;ANNs' are&lt;span style="color: #000000"&gt; &lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;"Error-Driven Classification"&lt;/strong&gt;&lt;/span&gt; classification models. Neurons are typically, but not always, arranged into&lt;span style="color: #000000"&gt;&lt;strong&gt; layers.&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 0.875rem;"&gt;The specific arrangement and connections between neurons is defined by the network's topology (shape).&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 0.875rem;"&gt;Most ANNs will have&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt; three or four fully-connected layers&lt;/strong&gt;&lt;/span&gt;&lt;span style="font-size: 0.875rem;"&gt;, or layers where each neuron in the layer connects to every neuron in the next layer.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;The below figure illustrates an artificial neural network with one hidden layer:&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693115_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;ANN example&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M8_ANN_example.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M8_ANN_example.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In these common topological, the first layer is the &lt;span style="color: #000000"&gt;&lt;strong&gt;input layer&lt;/strong&gt;&lt;/span&gt; and the last layer is the&lt;strong&gt; &lt;/strong&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;output layer&lt;/strong&gt;&lt;/span&gt;. Input data is fed directly to the input neurons, and the results of the algorithm are read from the output neurons.&lt;/p&gt;&lt;p&gt;In between the input and output layers, there are typically &lt;span style="color: #000000"&gt;&lt;strong&gt;a few hidden layers&lt;/strong&gt;&lt;/span&gt; made up of neurons that the user or programmer doesn't interact with directly.&lt;/p&gt;&lt;p&gt;The following diagram shows another neural network with three layers:&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693116_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;ANN example 2&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M8_another_ANN.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M8_another_ANN.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This network is capable of accepting &lt;span style="color: #000000"&gt;&lt;strong&gt;four different features&lt;/strong&gt;&lt;/span&gt; and can output &lt;span style="color: #000000"&gt;&lt;strong&gt;two pieces of information&lt;/strong&gt;&lt;/span&gt;.&lt;/p&gt;&lt;p&gt;A neuron takes a number of inputs and generates a single output based on&lt;span style="color: #000000"&gt;&lt;strong&gt; simple weighted sums&lt;/strong&gt;&lt;/span&gt; and a function called the &lt;span style="color: #000000"&gt;&lt;strong&gt;activation function&lt;/strong&gt;&lt;/span&gt;.&lt;/p&gt;&lt;p&gt;The way this works is that each neuron calculates the weighted sum and passes it to another function that decides to either fire i.e. transmit or not based on a threshold. Also, each neuron also has a bias. The bias does not apply to any one single input X (feature), but instead is added to the sum of the weighted inputs before the activation function is invoked.&lt;/p&gt;&lt;p&gt;The bias can be seen as a modifier to the threshold of the neuron's activation. The below figure illustrates:&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693117_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;neuron with bias&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M8_neuron_bias.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M8_neuron_bias.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Based on the above image:&lt;/p&gt;&lt;p&gt;Let &lt;strong&gt;w&lt;/strong&gt; be the weights vector:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;w = [w1, w2, w3]&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Let x be the input vector of features:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt; &lt;/span&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"&gt; &lt;semantics&gt; &lt;mstyle&gt; &lt;mi&gt;x &lt;/mi&gt; &lt;mo&gt;= &lt;/mo&gt; &lt;mfenced open="[" close="]"&gt; &lt;mtable&gt; &lt;mtr&gt; &lt;mtd&gt; &lt;msub&gt; &lt;mi&gt;x &lt;/mi&gt; &lt;mn&gt;1 &lt;/mn&gt; &lt;/msub&gt; &lt;/mtd&gt; &lt;/mtr&gt; &lt;mtr&gt; &lt;mtd&gt; &lt;msub&gt; &lt;mi&gt;x &lt;/mi&gt; &lt;mn&gt;2 &lt;/mn&gt; &lt;/msub&gt; &lt;/mtd&gt; &lt;/mtr&gt; &lt;mtr&gt; &lt;mtd&gt; &lt;msub&gt; &lt;mi&gt;x &lt;/mi&gt; &lt;mn&gt;3 &lt;/mn&gt; &lt;/msub&gt; &lt;/mtd&gt; &lt;/mtr&gt; &lt;/mtable&gt; &lt;/mfenced&gt; &lt;/mstyle&gt; &lt;annotation encoding="wiris"&gt;{"version":"1.1","math":"&amp;lt;math xmlns="http://www.w3.org/1998/Math/MathML"&amp;gt;&amp;lt;mi&amp;gt;x&amp;lt;/mi&amp;gt;&amp;lt;mo&amp;gt;=&amp;lt;/mo&amp;gt;&amp;lt;mfenced open="[" close="]"&amp;gt;&amp;lt;mtable&amp;gt;&amp;lt;mtr&amp;gt;&amp;lt;mtd&amp;gt;&amp;lt;msub&amp;gt;&amp;lt;mi&amp;gt;x&amp;lt;/mi&amp;gt;&amp;lt;mn&amp;gt;1&amp;lt;/mn&amp;gt;&amp;lt;/msub&amp;gt;&amp;lt;/mtd&amp;gt;&amp;lt;/mtr&amp;gt;&amp;lt;mtr&amp;gt;&amp;lt;mtd&amp;gt;&amp;lt;msub&amp;gt;&amp;lt;mi&amp;gt;x&amp;lt;/mi&amp;gt;&amp;lt;mn&amp;gt;2&amp;lt;/mn&amp;gt;&amp;lt;/msub&amp;gt;&amp;lt;/mtd&amp;gt;&amp;lt;/mtr&amp;gt;&amp;lt;mtr&amp;gt;&amp;lt;mtd&amp;gt;&amp;lt;msub&amp;gt;&amp;lt;mi&amp;gt;x&amp;lt;/mi&amp;gt;&amp;lt;mn&amp;gt;3&amp;lt;/mn&amp;gt;&amp;lt;/msub&amp;gt;&amp;lt;/mtd&amp;gt;&amp;lt;/mtr&amp;gt;&amp;lt;/mtable&amp;gt;&amp;lt;/mfenced&amp;gt;&amp;lt;/math&amp;gt;"} &lt;/annotation&gt; &lt;/semantics&gt; &lt;/math&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;b&lt;/span&gt; is the bias, &lt;span style="color: #000000"&gt;y&lt;/span&gt; the neuron’s output and f the activation function, then:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;y = w1x1+ w2x2+ w3x3+ b = f( w·x + b)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Activation functions takes the&amp;nbsp;weighted sum of inputs plus the bias as input&amp;nbsp;and perform the necessary computation to decide which nodes to fire in a layer. Notice from the equation above we are performing a vector &lt;span style="color: #000000"&gt;&lt;strong&gt;dot product&lt;/strong&gt;&lt;/span&gt;, more about this in the next topic.&lt;img src="https://s.brightspace.com/lib/emoticons/1.0.0/blush-light.svg" alt="blush with light skin tone emoticon"&gt;&lt;/p&gt;&lt;br&gt;&lt;h5&gt;References&lt;/h5&gt;&lt;ol&gt;&lt;li&gt;UC Berkeley CS188 Intro to AI&amp;nbsp;&lt;a href="http://ai.berkeley.edu/home.html"&gt;http://ai.berkeley.edu/home.html&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="http://www.cse.scu.edu/~tschwarz/coen266_09/PPT/Artificial%20Neural%20Networks.ppt"&gt;http://www.cse.scu.edu/~tschwarz/coen266_09/PPT/Artificial%20Neural%20Networks.ppt&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.kdnuggets.com/2017/07/introduction-neural-networks-advantages-applications.html"&gt;https://www.kdnuggets.com/2017/07/introduction-neural-networks-advantages-applications.html&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</TEXT><TYPE
   value="H"/></BODY><DATES><CREATED value="2024-10-04 18:31:46 EDT"/><UPDATED value="2024-11-13 23:47:16 EST"/><START
   value=""/><END value=""/></DATES><FLAGS><ISAVAILABLE value="true"/><ISFROMCARTRIDGE value="false"/><ISFOLDER
   value="false"/><ISDESCRIBED value="false"/><ISTRACKED value="true"/><ISLESSON value="false"/><ISSEQUENTIAL
   value="false"/><ALLOWGUESTS value="true"/><ALLOWOBSERVERS value="true"/><LAUNCHINNEWWINDOW
   value="false"/><ISREVIEWABLE value="false"/><ISGROUPCONTENT value="false"/><ISSAMPLECONTENT
   value="false"/><PARTIALLYVISIBLE value="false"/><HASTHUMBNAIL value="false"/></FLAGS><CONTENTHANDLER
  value="resource/x-bb-document"/><RENDERTYPE value="REGULAR"/><FOLDERTYPE value=""/><URL value=""/><VIEWMODE
  value="TEXT_ICON_ONLY"/><OFFLINENAME value=""/><OFFLINEPATH value=""/><LINKREF value=""/><PARENTID
  value="_800524_1"/><REVIEWABLEREASON value="NONE"/><VERSION value="3"/><THUMBNAILALT value=""/><AISTATE
  value="No"/><AIACCEPTINGUSER value=""/><EXTENDEDDATA/><FILES/></CONTENT>
