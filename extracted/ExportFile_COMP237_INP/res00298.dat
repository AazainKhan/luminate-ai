<?xml version="1.0" encoding="UTF-8"?>
<CONTENT id="_800660_1"><TITLE value="Topic 11.2: N-gram word models"/><TITLECOLOR value="#000000"/><DESCRIPTION
   value=""/><BODY><TEXT>&lt;div data-layout-row="395b487d-006e-440f-ac11-3e68cc29caf7"&gt;&lt;div data-layout-column="f0b6b0ee-30de-49d8-b6dc-0a3b8bb524a2" data-layout-column-width="12"&gt;&lt;div data-bbid="bbml-editor-id_dbc82644-c802-47e3-83cf-757df1d66305"&gt;&lt;p&gt;Topic 11.2: N-gram word models&lt;/p&gt;&lt;br&gt;&lt;h4&gt;&lt;span style="color: #1c8845"&gt;Language models&lt;/span&gt;&lt;/h4&gt;&lt;br&gt;&lt;p&gt;As we noted earlier bag of words had some issues. For example: the word &lt;span style="color: #000000"&gt;“quarter”&lt;/span&gt; is common in both business and sports.&lt;/p&gt;&lt;p&gt;But the four-word sequence :&lt;/p&gt;&lt;p&gt;“&lt;span style="color: #000000"&gt;First quarter earnings report&lt;/span&gt;” is only common in &lt;span style="color: #000000"&gt;business&lt;/span&gt;.&lt;/p&gt;&lt;p&gt;“&lt;span style="color: #000000"&gt;Fourth quarter touch down&lt;/span&gt;” is only common in &lt;span style="color: #000000"&gt;sports&lt;/span&gt;.&lt;/p&gt;&lt;p&gt;Watch this video then continue reading the topic:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;a href="https://mediasite.centennialcollege.ca/Mediasite/Play/3e041618c28d41dfb3cc3f0a6ae87d111d" data-bbtype="video" data-bbfile="{&amp;quot;src&amp;quot;:&amp;quot;https://mediasite.centennialcollege.ca/Mediasite/Play/3e041618c28d41dfb3cc3f0a6ae87d111d&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;https://mediasite.centennialcollege.ca/Mediasite/Play/3e041618c28d41dfb3cc3f0a6ae87d111d&amp;quot;}"&gt;https://mediasite.centennialcollege.ca/Mediasite/Play/3e041618c28d41dfb3cc3f0a6ae87d111d&lt;/a&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;As noted from the video, we can tweak the &lt;span style="color: #000000"&gt;&lt;strong&gt;bag-of-words&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;model to look at &lt;span style="color: #000000"&gt;&lt;strong&gt;a phrase of words&lt;/strong&gt;&lt;/span&gt; instead of one word. Then treat the phrase a single word. Well it is a bit more complicated,&lt;img src="https://s.brightspace.com/lib/emoticons/1.0.0/wink-light.svg" alt="wink with light skin tone emoticon"&gt;&lt;/p&gt;&lt;p&gt;We can compromise with a &lt;span style="color: #000000"&gt;&lt;strong&gt;Markov chain model&lt;/strong&gt;&lt;/span&gt; that considers only the dependency between &lt;span style="color: #000000"&gt;&lt;strong&gt;adjacent&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;words, we won't cover Marcov chains in this course, but it is a simple algorithm that predicts the future state in our case word based on the previous state i.e. previous word. This is known as the:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;N-gram model&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;Uni-gram&lt;/strong&gt;&lt;/span&gt; is the bag of words&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;Bi-gram&lt;/strong&gt;&lt;/span&gt; is to consider two words&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;Tri-gram&lt;/strong&gt;&lt;/span&gt; is to consider three words&lt;/p&gt;&lt;p&gt;Watch this short video to get more information about the power of N-grams&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;a href="https://www.youtube.com/embed/E_mN90TYnlg?feature=oembed&amp;amp;wmode=opaque&amp;amp;rel=0" data-bbtype="video" data-bbfile="{&amp;quot;src&amp;quot;:&amp;quot;https://www.youtube.com/embed/E_mN90TYnlg?feature=oembed&amp;amp;wmode=opaque&amp;amp;rel=0&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;https://www.youtube.com/embed/E_mN90TYnlg?feature=oembed&amp;amp;wmode=opaque&amp;amp;rel=0&amp;quot;}"&gt;https://www.youtube.com/embed/E_mN90TYnlg?feature=oembed&amp;amp;wmode=opaque&amp;amp;rel=0&lt;/a&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;Let us take an example of the following string of text:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;"This is a cat at the house"&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;The &lt;span style="color: #000000"&gt;&lt;strong&gt;unigram&lt;/strong&gt;&lt;/span&gt;&amp;nbsp;would look as follows: This, is , a, cat, at, the, house&lt;/p&gt;&lt;p&gt;The &lt;span style="color: #000000"&gt;&lt;strong&gt;Bigram&lt;/strong&gt;&lt;/span&gt; would look as follows: This is, is a, a cat, cat at, at the, the house&lt;/p&gt;&lt;p&gt;The&lt;span style="color: #000000"&gt;&lt;strong&gt; Trigram&lt;/strong&gt;&lt;/span&gt; would look as follows: This is a, is a cat, a cat at, cat at the, at the house&lt;/p&gt;&lt;p&gt;The figure below demonstrates such:&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693210_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;N gram models&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M11_n_grams.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;,&amp;quot;width&amp;quot;:887.4000244140625,&amp;quot;height&amp;quot;:306.29022179837335}"&gt;M11_n_grams.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Mathematically speaking we can represent the model as follows:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;P(w&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;&lt;sub&gt;j&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;|w&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;&lt;sub&gt;1:j-1&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;) = P(w&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;&lt;sub&gt;j&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;|w&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;&lt;sub&gt;j-n+1&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;:j&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;&lt;sub&gt;-1&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;P(w&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;&lt;sub&gt;1:N&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;) = &lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 2.25rem;"&gt;П&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;P(w&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;&lt;sub&gt;j&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;|w&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;&lt;sub&gt;j-n+1&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;:&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;&lt;sub&gt;j-1&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.5rem;"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;We can say in an &lt;span style="color: #000000"&gt;&lt;strong&gt;n-gram&lt;/strong&gt;&lt;/span&gt; model, the probability of each word is dependent on the n-1 previous words.&lt;/p&gt;&lt;h5&gt;N gram word models applications&lt;/h5&gt;&lt;p&gt;N-gram models work well for classifying:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Newspapers sections:&lt;/strong&gt; classifying politics from sports from business&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Spam e-mails:&lt;/strong&gt; classifying spam from non-spam&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Sentiment analysis:&lt;/strong&gt; classifying a movie or product review as positive or negative.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Author attribution:&lt;/strong&gt; classifying based on author style and vocabulary for example Faulkner of Shakespeare.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Remember our friend agent filtering spam e-mails:&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693211_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Agent filtering Spam e-mails&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M11_ngram_app_spam_agent.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;,&amp;quot;width&amp;quot;:310,&amp;quot;height&amp;quot;:266.3469387755102}"&gt;M11_ngram_app_spam_agent.png&lt;/a&gt;&lt;/p&gt;&lt;h5&gt;Issues with n-grams&lt;/h5&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693208_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Issues icon Ref:https://www.pxfuel.com/en/search?q=problem&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M11_issue.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M11_issue.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;High frequency n-grams like “of the” have high counts in the training corpus, so their probability is likely accurate.&lt;/p&gt;&lt;p&gt;Low frequency n-grams have low counts that are subject to noise; they have high variance.&lt;/p&gt;&lt;p&gt;Models will perform better if the variance is removed i.e. &lt;strong&gt;smooth out the variance&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;Another issue is out-of-vocabulary i.e. one that never appeared. Like our invisible man below:&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693212_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;invisible man Ref:https://www.publicdomainpictures.net/en/view-image.php?image=177691&amp;amp;picture=invisible-man&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M11_ngram_invisibleman.jpg&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/jpeg&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M11_ngram_invisibleman.jpg&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Should we give it a zero probability?&lt;/p&gt;&lt;p&gt;If your answer is Yes!&lt;/p&gt;&lt;p&gt;It is wrong because the probability of &lt;strong&gt;P(w&lt;/strong&gt;&lt;strong&gt;&lt;sub&gt;1:N&lt;/sub&gt;&lt;/strong&gt;&lt;strong&gt;)&lt;/strong&gt; the whole sentence would be zero.&lt;/p&gt;&lt;h5&gt;Solutions&lt;/h5&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693209_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Issue solution on the way Ref: https://www.pxfuel.com/en/free-photo-qhhjt&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M11_issue_solution.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M11_issue_solution.png&lt;/a&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Modify the training corpus by replacing unknown words with &amp;lt;UNK&amp;gt;, assign low probability.&lt;/li&gt;&lt;li&gt;Decide in advance to keep the most &lt;span style="color: #000000"&gt;50,000&lt;/span&gt; most common words.&lt;/li&gt;&lt;li&gt;Replace a string of digits with &lt;span style="color: #000000"&gt;&amp;lt;NUM&amp;gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;Replace an Email address with &lt;span style="color: #000000"&gt;&amp;lt;EMAIL&amp;gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;Mark start of text with &lt;span style="color: #000000"&gt;&amp;lt;S&amp;gt;&lt;/span&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;All of the above solutions and many others fall under the term &lt;span style="color: #000000"&gt;&lt;strong&gt;"Smoothing"&lt;/strong&gt;&lt;/span&gt; n-gram models.&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;h5&gt;References&lt;/h5&gt;&lt;ol&gt;&lt;li&gt;Chapter 23 Artificial intelligence a modern approach by Stuart J. Russell and Peter Norvig.&lt;/li&gt;&lt;li&gt;Chapter 15 Artificial Intelligence with Python. Second edition by Prateek Joshi&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</TEXT><TYPE
   value="H"/></BODY><DATES><CREATED value="2024-10-04 18:31:48 EDT"/><UPDATED value="2024-11-14 16:24:43 EST"/><START
   value=""/><END value=""/></DATES><FLAGS><ISAVAILABLE value="true"/><ISFROMCARTRIDGE value="false"/><ISFOLDER
   value="false"/><ISDESCRIBED value="false"/><ISTRACKED value="true"/><ISLESSON value="false"/><ISSEQUENTIAL
   value="false"/><ALLOWGUESTS value="true"/><ALLOWOBSERVERS value="true"/><LAUNCHINNEWWINDOW
   value="false"/><ISREVIEWABLE value="false"/><ISGROUPCONTENT value="false"/><ISSAMPLECONTENT
   value="false"/><PARTIALLYVISIBLE value="false"/><HASTHUMBNAIL value="false"/></FLAGS><CONTENTHANDLER
  value="resource/x-bb-document"/><RENDERTYPE value="REGULAR"/><FOLDERTYPE value=""/><URL value=""/><VIEWMODE
  value="TEXT_ICON_ONLY"/><OFFLINENAME value=""/><OFFLINEPATH value=""/><LINKREF value=""/><PARENTID
  value="_800543_1"/><REVIEWABLEREASON value="NONE"/><VERSION value="3"/><THUMBNAILALT value=""/><AISTATE
  value="No"/><AIACCEPTINGUSER value=""/><EXTENDEDDATA/><FILES/></CONTENT>
