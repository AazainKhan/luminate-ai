<?xml version="1.0" encoding="UTF-8"?>
<CONTENT id="_800679_1"><TITLE value="Topic 11.3 : Term Frequency - Inverse Document Frequency"/><TITLECOLOR
  value="#000000"/><DESCRIPTION
   value=""/><BODY><TEXT>&lt;div data-layout-row="25b7e8e8-6018-428d-9ec9-347ff959175f"&gt;&lt;div data-layout-column="78eadccc-ff95-48b5-b17f-4dffa4bdcb79" data-layout-column-width="12"&gt;&lt;div data-bbid="bbml-editor-id_6c070493-9a47-4f4d-872e-1a365994db6f"&gt;&lt;h4&gt;Topic 11.3: Term Frequency - Inverse Document Frequency&lt;/h4&gt;&lt;br&gt;&lt;h4&gt;&lt;span style="color: #1c8845"&gt;Language models&lt;/span&gt;&lt;/h4&gt;&lt;br&gt;&lt;p&gt;As we noted earlier bag of words had some issues. In the previous topic, we examined another option to represent language which is n-grams and noted that n-gram with &lt;span style="color: #000000"&gt;&lt;strong&gt;n-value&lt;/strong&gt;&lt;/span&gt; equal to &lt;span style="color: #000000"&gt;&lt;strong&gt;one&lt;/strong&gt;&lt;/span&gt; represents a &lt;span style="color: #000000"&gt;&lt;strong&gt;bag of words&lt;/strong&gt;&lt;/span&gt;.&lt;/p&gt;&lt;p&gt;Another variation of bag of words, is&lt;span style="color: #1c8845"&gt; &lt;/span&gt;&lt;span style="color: #1c8845"&gt;&lt;strong&gt;Term frequency-Inverse document frequency (TF/IDF)&lt;/strong&gt;&lt;/span&gt;. In this language model, we don't only look at the counts of words in a document, we also take into account the occurrence of the word &lt;span style="color: #000000"&gt;&lt;strong&gt;across the whole group of documents&lt;/strong&gt;&lt;/span&gt;.&lt;/p&gt;&lt;p&gt;This helps in formulating an idea about the &lt;span style="color: #000000"&gt;&lt;strong&gt;importance of a word&lt;/strong&gt;&lt;/span&gt; across a group of documents.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;em&gt;Let us see how:&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Goal: In a set of documents, we need to understand the importance of each word.&lt;/p&gt;&lt;p&gt;The tf-idf&amp;nbsp;metric&amp;nbsp;helps us to understand how important a given word is to a document in a set of documents.&lt;/p&gt;&lt;p&gt;&lt;span style="color: #1c8845"&gt;&lt;strong&gt;The Term Frequency (tf)&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;is basically a measure of how&amp;nbsp;frequently&amp;nbsp;each word appears in a given document. Since different documents have a different number of words, the exact numbers in the histogram will vary. In order to have a level playing field, we need to&amp;nbsp;normalize&amp;nbsp;the histograms. So, we divide the count of each word by the total number of words in a given document to obtain the term frequency.&lt;/p&gt;&lt;p&gt;&lt;span style="color: #1c8845"&gt;&lt;strong&gt;The Inverse Document Frequency (idf)&lt;/strong&gt;&lt;/span&gt;, which is a measure of how&amp;nbsp;unique&amp;nbsp;a word is to a document in a given&amp;nbsp;set of documents. To compute this statistic, we need to compute the&amp;nbsp;ratio of the number of documents with the given word and divide it by the total number of documents.&amp;nbsp;This ratio is essentially the fraction of the documents that contain the given word. Inverse document frequency is then calculated by taking the&amp;nbsp;negative&amp;nbsp;algorithm of this ratio.&lt;/p&gt;&lt;p&gt;Combine term frequency and inverse document frequency to formulate a&amp;nbsp;&lt;span style="color: #000000"&gt;&lt;strong&gt;feature vector&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;to categorize documents.&lt;/p&gt;&lt;p&gt;Watch this short video to get more information about how TF/IDF is calculated, there is a nice example.&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;a href="https://www.youtube.com/embed/zLMEnNbdh4Q?feature=oembed&amp;amp;wmode=opaque&amp;amp;rel=0" data-bbtype="video" data-bbfile="{&amp;quot;src&amp;quot;:&amp;quot;https://www.youtube.com/embed/zLMEnNbdh4Q?feature=oembed&amp;amp;wmode=opaque&amp;amp;rel=0&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;Term Frequency Inverse Document Frequency (TF-IDF) Explained&amp;quot;}"&gt;Term Frequency Inverse Document Frequency (TF-IDF) Explained&lt;/a&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;Mathematically speaking we can represent the model as follows:&lt;/p&gt;&lt;p&gt;&lt;span style="color: #1c8845"&gt;&lt;strong&gt;Term frequency:&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;The term frequency, tf(&lt;em&gt;t&lt;/em&gt;,&lt;em&gt;d&lt;/em&gt;), is the relative frequency of term&amp;nbsp;&lt;em&gt;t&lt;/em&gt;&amp;nbsp;within document&amp;nbsp;&lt;em&gt;d&lt;/em&gt;,&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-family: Open Sans;"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;tf (t,d) = ft,d / ∑ t&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-family: Open Sans;"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;&lt;sub&gt;' ∈d &lt;/sub&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-family: Open Sans;"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;f &lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-family: Open Sans;"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;&lt;sub&gt;t',d&lt;/sub&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;where&amp;nbsp;&lt;em&gt;f&lt;/em&gt;&lt;em&gt;&lt;sub&gt;t&lt;/sub&gt;&lt;/em&gt;&lt;sub&gt;,&lt;/sub&gt;&lt;em&gt;&lt;sub&gt;d&lt;/sub&gt;&lt;/em&gt;&amp;nbsp;is the&amp;nbsp;&lt;em&gt;raw count&lt;/em&gt;&amp;nbsp;of a term in a document, i.e., the number of times that term&amp;nbsp;t&amp;nbsp;occurs in document&amp;nbsp;d. Note the denominator is simply the total number of terms in document&amp;nbsp;&lt;em&gt;d&lt;/em&gt;&amp;nbsp;(counting each occurrence of the same term separately).&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;span style="color: #1c8845"&gt;&lt;strong&gt;Inverse Document Frequency&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;The&amp;nbsp;inverse document frequency is a measure of how much information the word provides, i.e., if it is &lt;span style="color: #000000"&gt;common&lt;/span&gt; or &lt;span style="color: #000000"&gt;rare&lt;/span&gt; across all documents. It is the logarithmically scaled inverse fraction of the documents that contain the word (obtained by dividing the total number of documents by the number of documents containing the term, and then taking the logarithm of that quotient):&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-family: Open Sans;"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;idf(t,D) = log&amp;nbsp;N/ |{d ∈ D : t ∈ d}|&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;em&gt;with&lt;/em&gt;&lt;/p&gt;&lt;ul&gt;&lt;li style="font-size: 1.125rem;
          padding-left: 1.487rem;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-family: Open Sans;"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;N&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;: total number of documents in the corpus&amp;nbsp;&lt;span style="color: #000000"&gt;&lt;span style="font-family: Open Sans;"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;N =|D|&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li style="font-size: 1.125rem;
          padding-left: 1.487rem;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-family: Open Sans;"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;|{d ∈ D : t ∈ d}|&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; : number of documents where the term &lt;span style="color: #000000"&gt;&lt;span style="font-family: Open Sans;"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;t&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; appears (i.e. &lt;span style="color: #000000"&gt;&lt;span style="font-family: Open Sans;"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;tf (t,d) &lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;≠ 0&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&amp;nbsp;&lt;/li&gt;&lt;li&gt;&amp;nbsp;&amp;nbsp;If the term is not in the corpus, this will lead to a division-by-zero. It is therefore common to adjust the denominator to&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;span style="color: #000000"&gt;&lt;span style="font-family: Open Sans;"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;1+&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-family: Open Sans;"&gt;&lt;span style="font-size: 1.125rem;"&gt; &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-family: Open Sans;"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;|{d ∈ D : t ∈ d}|&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;br&gt;&lt;h5&gt;References&lt;/h5&gt;&lt;ol&gt;&lt;li&gt;Chapter 15 Artificial Intelligence with Python. Second edition by Prateek Joshi&lt;/li&gt;&lt;li&gt;Wiki &lt;a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf"&gt;TF-IDF wikipedia&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Youtube &lt;a href="https://www.youtube.com/watch?v=zLMEnNbdh4Q"&gt;TF-IDF WhyML&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</TEXT><TYPE
   value="H"/></BODY><DATES><CREATED value="2024-10-04 18:31:48 EDT"/><UPDATED value="2024-11-14 16:40:05 EST"/><START
   value=""/><END value=""/></DATES><FLAGS><ISAVAILABLE value="true"/><ISFROMCARTRIDGE value="false"/><ISFOLDER
   value="false"/><ISDESCRIBED value="false"/><ISTRACKED value="true"/><ISLESSON value="false"/><ISSEQUENTIAL
   value="false"/><ALLOWGUESTS value="true"/><ALLOWOBSERVERS value="true"/><LAUNCHINNEWWINDOW
   value="false"/><ISREVIEWABLE value="false"/><ISGROUPCONTENT value="false"/><ISSAMPLECONTENT
   value="false"/><PARTIALLYVISIBLE value="false"/><HASTHUMBNAIL value="false"/></FLAGS><CONTENTHANDLER
  value="resource/x-bb-document"/><RENDERTYPE value="REGULAR"/><FOLDERTYPE value=""/><URL value=""/><VIEWMODE
  value="TEXT_ICON_ONLY"/><OFFLINENAME value=""/><OFFLINEPATH value=""/><LINKREF value=""/><PARENTID
  value="_800544_1"/><REVIEWABLEREASON value="NONE"/><VERSION value="3"/><THUMBNAILALT value=""/><AISTATE
  value="No"/><AIACCEPTINGUSER value=""/><EXTENDEDDATA/><FILES/></CONTENT>
