<?xml version="1.0" encoding="UTF-8"?>
<CONTENT id="_800693_1"><TITLE value="Topic 6.4 Training/ testing split &amp; K-fold"/><TITLECOLOR
  value="#000000"/><DESCRIPTION
   value=""/><BODY><TEXT>&lt;div data-layout-row="1faeecba-9da4-4425-8978-4f9089488483"&gt;&lt;div data-layout-column="f244f7fa-ba5d-4740-8901-531564449a87" data-layout-column-width="12"&gt;&lt;div data-bbid="bbml-editor-id_a87c2b05-dd97-4a2c-83f5-5d57df9a4ecd"&gt;&lt;h4&gt;Topic 6.4 Training/ testing split &amp;amp; k-fold&lt;/h4&gt;&lt;br&gt;&lt;h5&gt;&lt;span style="color: #1c8845"&gt;Training&amp;nbsp;and testing the model&lt;/span&gt;&lt;/h5&gt;&lt;br&gt;&lt;p&gt;Any predictive&amp;nbsp;model needs to be &lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;span style="text-decoration:underline;"&gt;validated&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;to see how it is performing on different sets of data, whether the accuracy of the model is constant over all the sources of similar data or not.&lt;/p&gt;&lt;p&gt;This checks the problem of over-fitting, wherein the model fits very well on one set of data but doesn't fit that well on another data set.&lt;/p&gt;&lt;p&gt;Methods to validate a model:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Train-test split of the data set.&lt;/li&gt;&lt;li&gt;K-fold cross validation.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Watch this video then continue reading:&lt;/p&gt;&lt;br&gt;&lt;p style="text-align: center;"&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693085_1" data-bbtype="attachment" data-bbfile="{&amp;quot;linkName&amp;quot;:&amp;quot;M6_kfold 4 August, 2020 - Loom Recording.mp4&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;video/mp4&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M6_kfold 4 August, 2020 - Loom Recording.mp4&lt;/a&gt;&lt;/p&gt;&lt;br&gt;&lt;h5&gt;&lt;span style="color: #1c8845"&gt;Train-test split&lt;/span&gt;&lt;/h5&gt;&lt;br&gt;&lt;p&gt;Ideally, this&amp;nbsp;step should be done right at the onset of the modelling process so that there are no &lt;span style="color: #000000"&gt;&lt;strong&gt;sampling biases&lt;/strong&gt;&lt;/span&gt; in the model.&lt;/p&gt;&lt;p&gt;Usually the data is split into &lt;span style="color: #000000"&gt;&lt;strong&gt;(60%-80%)&lt;/strong&gt;&lt;/span&gt; for training and &lt;span style="color: #000000"&gt;&lt;strong&gt;(40%-20%)&lt;/strong&gt;&lt;/span&gt; for testing.&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693086_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Splitting the data into train test&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M6_train_test.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M6_train_test.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In other words, the model &lt;span style="color: #000000"&gt;&lt;strong&gt;should perform wel&lt;/strong&gt;&lt;/span&gt;l even for a data set that has&amp;nbsp;&lt;span style="color: #000000"&gt;&lt;strong&gt;the same predictor variables (features)&lt;/strong&gt;&lt;/span&gt;, but&amp;nbsp;their &lt;span style="color: #000000"&gt;&lt;strong&gt;means and variances are very different&lt;/strong&gt;&lt;/span&gt; from what the model has been built upon. This can happen because the data set on which the model is built (training) and the one on which it is applied (testing) can come from different sources.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The following is a description of the two types of datasets:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;The &lt;span style="color: #000000"&gt;&lt;strong&gt;training data set&lt;/strong&gt;&lt;/span&gt; is the one on which the model is built. This is the one on which the calculations are performed and the model equations and parameters (weights) are created.&lt;/li&gt;&lt;li&gt;The &lt;span style="color: #000000"&gt;&lt;strong&gt;testing data set&lt;/strong&gt;&lt;/span&gt; is used to check the accuracy of the model. The model equations and parameters are used to calculate the output based on the inputs from the testing datasets. These outputs are used to compare the model efficiency in the light of the actuals present in the testing data set.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The below figure illustrate the use of these data-sets.&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693087_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Concept of training and testing models using data&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M6_train_test_concept.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M6_train_test_concept.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We use random sampling to create the train test, in addition to some built in methods from the sickit to create these samples.&lt;/p&gt;&lt;h5&gt;&lt;span style="color: #1c8845"&gt;K-fold cross validation&lt;/span&gt;&lt;/h5&gt;&lt;br&gt;&lt;p&gt;A more robust way to split the data and avoid the sampling bias is a process called the k-fold cross validation.&lt;/p&gt;&lt;p&gt;In &lt;strong&gt;k-fold cross-validation&lt;/strong&gt;, the training sample is randomly partitioned into &lt;span style="color: #000000"&gt;&lt;strong&gt;k&lt;/strong&gt;&lt;/span&gt; equal size sub-samples. Of the &lt;span style="color: #000000"&gt;&lt;strong&gt;k&lt;/strong&gt;&lt;/span&gt; sub-samples, a single sub-sample is retained as the validation data for testing the model, and the remaining &lt;span style="color: #000000"&gt;&lt;strong&gt;k-1&lt;/strong&gt;&lt;/span&gt; sub-samples are used as training data.&lt;/p&gt;&lt;p&gt;The cross-validation process is then repeated &lt;span style="color: #000000"&gt;&lt;strong&gt;k&lt;/strong&gt;&lt;/span&gt; times (the folds), with each of the &lt;span style="color: #000000"&gt;&lt;strong&gt;k&lt;/strong&gt;&lt;/span&gt; sub-samples used exactly once as the validation data.&lt;/p&gt;&lt;p&gt;The &lt;span style="color: #000000"&gt;&lt;strong&gt;k&lt;/strong&gt;&lt;/span&gt; results from the folds can then be &lt;span style="color: #000000"&gt;&lt;strong&gt;averaged&lt;/strong&gt;&lt;/span&gt; (or otherwise combined) to produce a &lt;span style="color: #000000"&gt;&lt;strong&gt;single estimation&lt;/strong&gt;&lt;/span&gt;.&lt;/p&gt;&lt;p&gt;The most commonly used is &lt;span style="color: #000000"&gt;&lt;strong&gt;10-fold&lt;/strong&gt;&lt;/span&gt;. The below figure illustrated the k-fold approach.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693088_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;k-fold cross validation&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M6_kfold.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M6_kfold.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;As noted from the figure, each round has one test set indicated in yellow and the remaining 9 sets indicated in blue are used for training.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The advantage of this method is that &lt;span style="color: #000000"&gt;&lt;strong&gt;all observations&lt;/strong&gt;&lt;/span&gt; are used for both &lt;span style="color: #000000"&gt;&lt;strong&gt;training and validation&lt;/strong&gt;&lt;/span&gt;, and each observation is used for validation &lt;span style="color: #000000"&gt;&lt;strong&gt;exactly once.&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;h5&gt;References&lt;/h5&gt;&lt;ol&gt;&lt;li&gt;Chapter 3 &lt;span style="font-family: Open Sans;"&gt;&lt;span style="font-size: 0.875rem;"&gt;Python: Advanced Predictive Analytics, by Joseph Babcock and Ashish Kumar. &lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.openml.org/a/estimation-procedures/1"&gt;https://www.openml.org/a/estimation-procedures/1&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</TEXT><TYPE
   value="H"/></BODY><DATES><CREATED value="2024-10-04 18:31:46 EDT"/><UPDATED value="2024-11-13 23:24:58 EST"/><START
   value=""/><END value=""/></DATES><FLAGS><ISAVAILABLE value="true"/><ISFROMCARTRIDGE value="false"/><ISFOLDER
   value="false"/><ISDESCRIBED value="false"/><ISTRACKED value="true"/><ISLESSON value="false"/><ISSEQUENTIAL
   value="false"/><ALLOWGUESTS value="true"/><ALLOWOBSERVERS value="true"/><LAUNCHINNEWWINDOW
   value="false"/><ISREVIEWABLE value="false"/><ISGROUPCONTENT value="false"/><ISSAMPLECONTENT
   value="false"/><PARTIALLYVISIBLE value="false"/><HASTHUMBNAIL value="false"/></FLAGS><CONTENTHANDLER
  value="resource/x-bb-document"/><RENDERTYPE value="REGULAR"/><FOLDERTYPE value=""/><URL value=""/><VIEWMODE
  value="TEXT_ICON_ONLY"/><OFFLINENAME value=""/><OFFLINEPATH value=""/><LINKREF value=""/><PARENTID
  value="_800519_1"/><REVIEWABLEREASON value="NONE"/><VERSION value="3"/><THUMBNAILALT value=""/><AISTATE
  value="No"/><AIACCEPTINGUSER value=""/><EXTENDEDDATA/><FILES/></CONTENT>
