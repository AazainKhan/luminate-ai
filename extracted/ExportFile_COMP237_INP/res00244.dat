<?xml version="1.0" encoding="UTF-8"?>
<CONTENT id="_800699_1"><TITLE value="Topic 5.5 Linear Regression"/><TITLECOLOR value="#000000"/><DESCRIPTION
   value=""/><BODY><TEXT>&lt;div data-layout-row="50eff856-2a0e-427e-987e-af65a3c094d2"&gt;&lt;div data-layout-column="e381072c-2df9-45d4-bc12-cd97a716a506" data-layout-column-width="12"&gt;&lt;div data-bbid="bbml-editor-id_63e86d42-8deb-45a2-92c2-ff746a942bbb"&gt;&lt;h4&gt;&lt;span style="color: #1c8845"&gt;Linear Regression&amp;nbsp;&lt;/span&gt;&lt;/h4&gt;&lt;br&gt;&lt;h5&gt;Uni-variate Linear Regression&lt;/h5&gt;&lt;br&gt;&lt;p&gt;A uni-variate linear model : A straight line with input x and output y has the form:&lt;/p&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693037_1" data-bbtype="attachment" data-bbfile="{&amp;quot;linkName&amp;quot;:&amp;quot;PastedImage_megh4ek1oi3lpl105tw3xbb93xm3ge5o001100779931.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;PastedImage_megh4ek1oi3lpl105tw3xbb93xm3ge5o001100779931.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;w&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt; &amp;amp; w&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/strong&gt;&lt;/span&gt; are real valued coefficients of the model that need to be &lt;span style="color: #000000"&gt;&lt;strong&gt;learned&lt;/strong&gt;&lt;/span&gt;. The figure below illustrates the linear model for one variable x. &lt;span style="color: #000000"&gt;&lt;strong&gt;w&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;/strong&gt;&lt;/span&gt; is the intercept on the y axis and &lt;span style="color: #000000"&gt;&lt;strong&gt;w&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;is the slope.&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693038_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Linear model&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M5_linear_slope.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M5_linear_slope.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Watch this video then continue reading:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;a href="https://mediasite.centennialcollege.ca/Mediasite/Play/64d5b372e3c74979b6b560f39a3f8a411d" data-bbtype="video" data-bbfile="{&amp;quot;src&amp;quot;:&amp;quot;https://mediasite.centennialcollege.ca/Mediasite/Play/64d5b372e3c74979b6b560f39a3f8a411d&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;https://mediasite.centennialcollege.ca/Mediasite/Play/64d5b372e3c74979b6b560f39a3f8a411d&amp;quot;}"&gt;https://mediasite.centennialcollege.ca/Mediasite/Play/64d5b372e3c74979b6b560f39a3f8a411d&lt;/a&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;The task is finding the &lt;span style="color: #000000"&gt;&lt;strong&gt;h&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;sub&gt;w&lt;/sub&gt;&lt;/strong&gt;&lt;/span&gt; that&lt;span style="color: #000000"&gt;&lt;strong&gt; best fits&lt;/strong&gt;&lt;/span&gt; all the data points. In order to do that we will use the &lt;span style="color: #000000"&gt;&lt;strong&gt;L&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;sub&gt;2&lt;/sub&gt;&lt;/strong&gt;&lt;/span&gt; loss function.&amp;nbsp;&lt;/p&gt;&lt;p&gt;This is reflected in the below equation:&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693039_1" data-bbtype="attachment" data-bbfile="{&amp;quot;linkName&amp;quot;:&amp;quot;PastedImage_u5gb05lx4qbzttqcppa08vsbhrlk9q25001100779931.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;PastedImage_u5gb05lx4qbzttqcppa08vsbhrlk9q25001100779931.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Have a look at the below figure, which reflects the &lt;strong&gt;Ordinary Least Squares (OLS)&lt;/strong&gt;, the blue line is our machine learning model, the black dots are our observationsn and the red lines are the difference between the actual and predicted values.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693040_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Linear least squares&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M5_linear_SS.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M5_linear_SS.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693041_1" data-bbtype="attachment" data-bbfile="{&amp;quot;linkName&amp;quot;:&amp;quot;PastedImage_sxgurx5nv6vmbpuvjtgv09wj6esaz245001100779931.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;PastedImage_sxgurx5nv6vmbpuvjtgv09wj6esaz245001100779931.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;There are many possibilities to plot the lines, each possibility will yield different weights as per the figure below:&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693042_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;many options for best fit line&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;ct9uc5nbzlxd1us0sb3bnqfedhzs0liw001100779931(1).png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;ct9uc5nbzlxd1us0sb3bnqfedhzs0liw001100779931(1).png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;SS residuals&lt;/strong&gt;&lt;/span&gt; is the loss function &lt;span style="color: #000000"&gt;&lt;strong&gt;L&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;sub&gt;2&lt;/sub&gt;&lt;/strong&gt;&lt;/span&gt;. We need to minimize the loss function Summed over the training data.&lt;/p&gt;&lt;p&gt;If we plot the weight space in a 3D where all the&lt;span style="color: #000000"&gt;&lt;strong&gt; w&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;/strong&gt;&lt;/span&gt; and &lt;span style="color: #000000"&gt;&lt;strong&gt;w&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/strong&gt;&lt;/span&gt; options are plotted against their respective loss values, we will notice a&lt;span style="color: #000000"&gt;&lt;strong&gt; convex&lt;/strong&gt;&lt;/span&gt; shape of the loss function and we need to reach to the lowest point on the convex function as per the below figure.&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693043_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;weight space and L2 loss function&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M5_linear_loss.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M5_linear_loss.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We can actually solve this problem mathematically. The sum is minimized when its &lt;span style="color: #000000"&gt;&lt;strong&gt;partial derivatives&lt;/strong&gt;&lt;/span&gt; with respect to &lt;span style="color: #000000"&gt;&lt;strong&gt;w&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;/strong&gt;&lt;/span&gt; and &lt;span style="color: #000000"&gt;&lt;strong&gt;w&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/strong&gt;&lt;/span&gt; are zero.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693044_1" data-bbtype="attachment" data-bbfile="{&amp;quot;linkName&amp;quot;:&amp;quot;PastedImage_la9nyeig4f6ueoxxu64eisd5k6ww2bln001100779931.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;PastedImage_la9nyeig4f6ueoxxu64eisd5k6ww2bln001100779931.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Using the Chain rule we can calculate the values of &lt;span style="color: #000000"&gt;&lt;strong&gt;w&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;/strong&gt;&lt;/span&gt; and &lt;span style="color: #000000"&gt;&lt;strong&gt;w&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/strong&gt;&lt;/span&gt;, as follows:&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693045_1" data-bbtype="attachment" data-bbfile="{&amp;quot;linkName&amp;quot;:&amp;quot;PastedImage_jnq2rnvvq7a8hod829fnjgth37ymd82c001100779931.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;PastedImage_jnq2rnvvq7a8hod829fnjgth37ymd82c001100779931.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Assume we have the housing prices and house sizes data points as per the below figure:&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693046_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Univariate linear regression model for housing prices and housing sizes&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M5_housing.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;,&amp;quot;width&amp;quot;:997.4000244140625,&amp;quot;height&amp;quot;:434.95033019777395}"&gt;M5_housing.png&lt;/a&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;span style="font-size: 1.125rem;"&gt;We can solve this by using the equations and find the weights &lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;w&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size: 1.125rem;"&gt; and &lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;w&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="font-size: 1.125rem;"&gt; as follows:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693047_1" data-bbtype="attachment" data-bbfile="{&amp;quot;linkName&amp;quot;:&amp;quot;PastedImage_fwost0z602ajnk4wa78ef7flss29skop001100779931.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;,&amp;quot;width&amp;quot;:788,&amp;quot;height&amp;quot;:248.34380776340112}"&gt;PastedImage_fwost0z602ajnk4wa78ef7flss29skop001100779931.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Once we find the best fit line using &lt;strong&gt;least square sum of the difference&lt;/strong&gt;&lt;span style="text-decoration:underline;"&gt;,&lt;/span&gt; &lt;span style="color: #000000"&gt;&lt;strong&gt;w0&lt;/strong&gt;&lt;/span&gt; and &lt;span style="color: #000000"&gt;&lt;strong&gt;w1&lt;/strong&gt;&lt;/span&gt; are determined and we can predicted the expected value of a new data point using the model equation. Usually the calculations for the &lt;strong&gt;least square sum of the difference&lt;/strong&gt;&amp;nbsp;are done through computer programs and there are ready-made libraries of methods to carry out the calculations in most of the programming languages.&lt;/p&gt;&lt;p&gt;If you are interested to see how it is done manually check out this link, for an example:&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.varsitytutors.com/hotmath/hotmath_help/topics/line-of-best-fit"&gt;https://www.varsitytutors.com/hotmath/hotmath_help/topics/line-of-best-fit&lt;/a&gt;&lt;/p&gt;&lt;h5&gt;&lt;span style="color: #1c8845"&gt;Linear Regression How do we measure model efficacy?&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;As we have seen the model weights depend on the historical data (observations). Different sets will lead into different values for the model.&lt;/p&gt;&lt;p&gt;But how do we measure the efficacy of our model?&amp;nbsp;&lt;/p&gt;&lt;p&gt;The answer is to use &lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;R&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;strong&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;sup&gt;&amp;nbsp;&lt;/sup&gt;:&lt;/p&gt;&lt;p&gt;The value of&amp;nbsp;&lt;span style="color: #000000"&gt;&lt;strong&gt;R&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/strong&gt;&lt;/span&gt;&amp;nbsp;can range from &lt;span style="color: #000000"&gt;&lt;strong&gt;0&lt;/strong&gt;&lt;/span&gt; to &lt;span style="color: #000000"&gt;&lt;strong&gt;1&lt;/strong&gt;&lt;/span&gt;. The &lt;span style="color: #000000"&gt;&lt;strong&gt;closer it is to 1, the better the model&lt;/strong&gt;&lt;/span&gt;.&lt;/p&gt;&lt;h6&gt;What is &lt;span style="color: #000000"&gt;&lt;strong&gt;R&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/strong&gt;&lt;/span&gt;&amp;nbsp;?&lt;/h6&gt;&lt;p&gt;Assume that we don’t have any predictor model, so our best bet is to go with the mean value of the observed value and say that this will be the predicted value. The mean line (y&lt;sub&gt;avg&lt;/sub&gt;), which is the green line in the below figure, would be the worst case scenario:&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693048_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;R squared&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M5_R2.jpg&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/jpeg&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M5_R2.jpg&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In this case, there is no model and the total variability is explained as the &lt;strong&gt;Total Sum of Squares&lt;/strong&gt; or &lt;strong&gt;SST&lt;/strong&gt;:&lt;/p&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693049_1" data-bbtype="attachment" data-bbfile="{&amp;quot;linkName&amp;quot;:&amp;quot;PastedImage_syn2r69bd8u1i30gl0axm252gefcbif9001100779931.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;PastedImage_syn2r69bd8u1i30gl0axm252gefcbif9001100779931.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The total error SST is composed of two terms:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;The difference between the regression&amp;nbsp;value and the mean value, this is the difference which the model seeks to explain and is called &lt;strong&gt;Regression Sum of Squares&lt;/strong&gt; or &lt;strong&gt;SSR&lt;/strong&gt;.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693050_1" data-bbtype="attachment" data-bbfile="{&amp;quot;linkName&amp;quot;:&amp;quot;PastedImage_io5nffw1hayugkippmbmebjs43flb29z001100779931.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;PastedImage_io5nffw1hayugkippmbmebjs43flb29z001100779931.png&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;The unexplained random term called, &lt;strong&gt;Difference Sum of Squares&lt;/strong&gt; or &lt;strong&gt;SSD&lt;/strong&gt;.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693051_1" data-bbtype="attachment" data-bbfile="{&amp;quot;linkName&amp;quot;:&amp;quot;PastedImage_jhblb6vpfzvau2lxuf1sb58l0n0p3qjp001100779931.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;PastedImage_jhblb6vpfzvau2lxuf1sb58l0n0p3qjp001100779931.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The more the share of SSR in SST, the better the model is. This share is quantified by something called&amp;nbsp;&lt;span style="color: #000000"&gt;&lt;strong&gt;R&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/strong&gt;&lt;/span&gt;&amp;nbsp;or &lt;strong&gt;coefficient of determination&lt;/strong&gt;, as follows:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;R&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&amp;nbsp;&amp;nbsp;= 1- (SSR/SST)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Apart&amp;nbsp;from the&amp;nbsp;&lt;span style="color: #000000"&gt;&lt;strong&gt;R&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/strong&gt;&lt;/span&gt;&amp;nbsp;statistic, there are other statistics and parameters.&lt;/p&gt;&lt;h5&gt;&lt;span style="color: #000000"&gt;P-values&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;Remember that the calculation of &lt;span style="color: #000000"&gt;&lt;strong&gt;w&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;/strong&gt;&lt;/span&gt; and &lt;span style="color: #000000"&gt;&lt;strong&gt;w&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/strong&gt;&lt;/span&gt; are &lt;span style="color: #000000"&gt;&lt;strong&gt;estimates&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;and not exact values. Whether their values are significant or not, needs to be tested using a hypothesis test.&lt;/p&gt;&lt;p&gt;The hypothesis tests whether the value of &lt;span style="color: #000000"&gt;&lt;strong&gt;w&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/strong&gt;&lt;/span&gt; is non-zero or not; if there is, the &lt;span style="color: #000000"&gt;&lt;strong&gt;w&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/strong&gt;&lt;/span&gt; will be non-zero. In the equation y= w&lt;sub&gt;0&lt;/sub&gt; +w&lt;sub&gt;1&lt;/sub&gt;*x, if we put w&lt;sub&gt;1&lt;/sub&gt; = 0, there will be no relation between &lt;strong&gt;y&lt;/strong&gt; and &lt;strong&gt;x&lt;/strong&gt;. The hypothesis test is defined, as follows:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;Null Hypothesis H&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt; : w&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt; =0&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;Alternate Hypothesis H&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;a&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt; : w&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt; &amp;lt;&amp;gt; 0&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left;"&gt;&lt;span style="font-size: 0.875rem;"&gt;So, whenever a&amp;nbsp;regression task is performed and&amp;nbsp;&lt;/span&gt;&lt;span style="font-size: 0.875rem;"&gt;&lt;strong&gt;β&lt;/strong&gt;&lt;/span&gt;&lt;span style="font-size: 0.875rem;"&gt;&amp;nbsp;is calculated, there will be an accompanying t-statistic and a p-value corresponding to this hypothesis test, calculated automatically by the program.&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;&lt;span style="color: #1c8845"&gt;Multivariate linear regression&lt;/span&gt;&lt;/h4&gt;&lt;br&gt;&lt;p&gt;We can easily extend to multivariate linear regression problems, in which each example &lt;strong&gt;x&lt;/strong&gt;&lt;strong&gt;&lt;sub&gt;j&lt;/sub&gt;&lt;/strong&gt; is an n-element vector. Our hypothesis space is the set of functions of the form:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="font-size: 1.125rem;"&gt;h&lt;/span&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;sw&lt;/sub&gt;&lt;/span&gt;&lt;span style="font-size: 1.125rem;"&gt;(x&lt;/span&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;j&lt;/sub&gt;&lt;/span&gt;&lt;span style="font-size: 1.125rem;"&gt;) = w&lt;/span&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;/span&gt;&lt;span style="font-size: 1.125rem;"&gt; + w&lt;/span&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/span&gt;&lt;span style="font-size: 1.125rem;"&gt;x&lt;/span&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;j,1&lt;/sub&gt;&lt;/span&gt;&lt;span style="font-size: 1.125rem;"&gt; + · · · + w&lt;/span&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;n&lt;/sub&gt;&lt;/span&gt;&lt;span style="font-size: 1.125rem;"&gt;x&lt;/span&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;j,n&lt;/sub&gt;&lt;/span&gt;&lt;span style="font-size: 1.125rem;"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 0.875rem;"&gt;Multivariate linear regression is actually not much more complicated than the univariate case. The loss function can be a gradient descent that we will cover in future lessons.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;With univariate linear regression, we didn’t have to worry about&lt;span style="color: #000000"&gt;&lt;strong&gt; overfitting&lt;/strong&gt;&lt;/span&gt;. But with multivariate linear regression in high-dimensional spaces, it is possible that some dimension, that is actually irrelevant appears by chance to be useful, resulting in &lt;span style="color: #000000"&gt;&lt;strong&gt;overfitting.&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;h5&gt;References&lt;/h5&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Artificial intelligence a modern approach&amp;nbsp;&lt;/strong&gt;by Stuart J. Russell and Peter Norvig. Chapter 19.&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</TEXT><TYPE
   value="H"/></BODY><DATES><CREATED value="2024-10-04 18:31:45 EDT"/><UPDATED value="2024-11-11 23:04:37 EST"/><START
   value=""/><END value=""/></DATES><FLAGS><ISAVAILABLE value="true"/><ISFROMCARTRIDGE value="false"/><ISFOLDER
   value="false"/><ISDESCRIBED value="false"/><ISTRACKED value="true"/><ISLESSON value="false"/><ISSEQUENTIAL
   value="false"/><ALLOWGUESTS value="true"/><ALLOWOBSERVERS value="true"/><LAUNCHINNEWWINDOW
   value="false"/><ISREVIEWABLE value="false"/><ISGROUPCONTENT value="false"/><ISSAMPLECONTENT
   value="false"/><PARTIALLYVISIBLE value="false"/><HASTHUMBNAIL value="false"/></FLAGS><CONTENTHANDLER
  value="resource/x-bb-document"/><RENDERTYPE value="REGULAR"/><FOLDERTYPE value=""/><URL value=""/><VIEWMODE
  value="TEXT_ICON_ONLY"/><OFFLINENAME value=""/><OFFLINEPATH value=""/><LINKREF value=""/><PARENTID
  value="_800513_1"/><REVIEWABLEREASON value="NONE"/><VERSION value="3"/><THUMBNAILALT value=""/><AISTATE
  value="No"/><AIACCEPTINGUSER value=""/><EXTENDEDDATA/><FILES/></CONTENT>
