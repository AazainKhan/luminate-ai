<?xml version="1.0" encoding="UTF-8"?>
<CONTENT id="_800672_1"><TITLE value="Topic 8.3: Perceptrons"/><TITLECOLOR value="#000000"/><DESCRIPTION
   value=""/><BODY><TEXT>&lt;div data-layout-row="23d6947f-551e-41c0-a070-534f7e98235b"&gt;&lt;div data-layout-column="246d9b50-f642-42d9-9816-21bca99bceb9" data-layout-column-width="12"&gt;&lt;div data-bbid="bbml-editor-id_e4b80230-8138-448c-865f-b3f7f2224f9a"&gt;&lt;h4&gt;Topic 8.3: Perceptrons&lt;/h4&gt;&lt;br&gt;&lt;h5&gt;&lt;span style="color: #1c8845"&gt;Perceptrons&lt;/span&gt;&lt;/h5&gt;&lt;br&gt;&lt;p&gt;The original model for an artificial neuron was called the perceptron (Rosenblatt, 1958), and its activation function was a step function, that operated as a linear classifier.&lt;/p&gt;&lt;p&gt;Watch this video to learn about perceptrons then continue reading.&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;a href="https://mediasite.centennialcollege.ca/Mediasite/Play/168e0e6139ce49dcb2645e503e9159001d" data-bbtype="video" data-bbfile="{&amp;quot;src&amp;quot;:&amp;quot;https://mediasite.centennialcollege.ca/Mediasite/Play/168e0e6139ce49dcb2645e503e9159001d&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;https://mediasite.centennialcollege.ca/Mediasite/Play/168e0e6139ce49dcb2645e503e9159001d&amp;quot;}"&gt;https://mediasite.centennialcollege.ca/Mediasite/Play/168e0e6139ce49dcb2645e503e9159001d&lt;/a&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;As noted in the video, the perceptron is using a step function with the following rule:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;if for a neuron, &lt;span style="color: #000000"&gt;w·x + b &amp;gt; 0&lt;/span&gt; the neuron would output &lt;span style="color: #000000"&gt;1&lt;/span&gt;.&lt;/li&gt;&lt;li&gt;If for a neuron,&lt;span style="color: #000000"&gt; w·x + b &amp;lt; 0&lt;/span&gt; the neuron would output &lt;span style="color: #000000"&gt;0&lt;/span&gt;.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This could be plotted as follows:&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693134_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;step function&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M8_step_function.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M8_step_function.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The figure below illustrates the perceptron structure:&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693135_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Perceptron structure&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M8_perceptron.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;,&amp;quot;width&amp;quot;:645.4000244140625,&amp;quot;height&amp;quot;:278.83061262719895}"&gt;M8_perceptron.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The perceptron is a&lt;span style="color: #000000"&gt;&lt;strong&gt; Binary Linear Classifier:&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;hw(x) = 1 if w.x &amp;gt;= 0 else 0&lt;/p&gt;&lt;p&gt;Alternatively:&lt;/p&gt;&lt;p style="text-align: center;"&gt;hw(x) = threshold(w.x) where threshold (z) = 1 if z&amp;gt;= 0 else 0&lt;/p&gt;&lt;p&gt;The main issue is to find the weight vector &lt;span style="color: #000000"&gt;&lt;strong&gt;w&lt;/strong&gt;&lt;/span&gt;. Think to of choosing &lt;span style="color: #000000"&gt;&lt;strong&gt;w&lt;/strong&gt;&lt;/span&gt; to&lt;span style="color: #000000"&gt;&lt;strong&gt; minimize the loss&lt;/strong&gt;&lt;/span&gt;:&lt;/p&gt;&lt;p&gt;Both the true value y and the hypothesis output h&lt;sub&gt;w&lt;/sub&gt;(x) are either 0 or 1, so there are 3 possibilities:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&amp;nbsp;If the output is correct, i.e., y =h&lt;sub&gt;w&lt;/sub&gt;(x), then the weights are&lt;span style="color: #000000"&gt; not changed.&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&amp;nbsp;If&lt;span style="color: #000000"&gt; y&lt;/span&gt; is &lt;span style="color: #000000"&gt;1&lt;/span&gt; but &lt;span style="color: #000000"&gt;h&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;sub&gt;w&lt;/sub&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;(x)&lt;/span&gt; is &lt;span style="color: #000000"&gt;0&lt;/span&gt;, then &lt;span style="color: #000000"&gt;wi&lt;/span&gt; is&lt;span style="color: #000000"&gt; increased&lt;/span&gt; when the corresponding input xi is positive and decreased when xi is negative. This makes sense, because we want to make w · x bigger so that h&lt;sub&gt;w&lt;/sub&gt;(x) outputs a 1.&lt;/li&gt;&lt;li&gt;&amp;nbsp;If &lt;span style="color: #000000"&gt;y&lt;/span&gt; is &lt;span style="color: #000000"&gt;0&lt;/span&gt; but&lt;span style="color: #000000"&gt; h&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;sub&gt;w&lt;/sub&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt; (x)&lt;/span&gt; is &lt;span style="color: #000000"&gt;1&lt;/span&gt;, then &lt;span style="color: #000000"&gt;wi&lt;/span&gt; is &lt;span style="color: #000000"&gt;decreased&lt;/span&gt; when the corresponding input xi is positive and increased when xi is negative. This makes sense, because we want to make w · x smaller so that h&lt;sub&gt;w&lt;/sub&gt; (x) outputs a 0.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Based on the above, there is a simple update rule for the weights update:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt; ← w&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt; + α (y- hw(x)) * x&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;y is the actual value&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;α is the learning rate&amp;nbsp;&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In the next topic we will dive more into the derivation of this rule.&lt;/p&gt;&lt;p&gt;The perceptron&amp;nbsp;model is good for representing logic gates (AND), (OR) and (NAND), but when it comes to the (XOR) it does not perform that well at a standard learning rate as per the below figure:&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693136_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;AND OR XOR gates&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M8_AND_OR.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;,&amp;quot;width&amp;quot;:914.4000244140625,&amp;quot;height&amp;quot;:284.5067316138184}"&gt;M8_AND_OR.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The main reason is the data in the (XOR) gate is not linearly separable, as noted in the above figure we need to draw two decision boundries to separate the data.&lt;/p&gt;&lt;p&gt;Despite that the perceptrons have played&amp;nbsp;a core role in neural networks. The perceptron learning rule converges into&amp;nbsp;perfect linear separator when data points are &lt;span style="color: #000000"&gt;&lt;strong&gt;separable&lt;/strong&gt;&lt;/span&gt;.&amp;nbsp;&lt;/p&gt;&lt;p&gt;If data id &lt;span style="color: #000000"&gt;&lt;strong&gt;not separable&lt;/strong&gt;&lt;/span&gt;, researches have shown that &lt;span style="color: #000000"&gt;&lt;strong&gt;adjusting the learning rate&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 0.875rem;"&gt;&lt;strong&gt;α&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt; will allow the rule to converge to a minimum error rate. This is beyond this course.&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693137_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;data separability&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M8_problem1.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M8_problem1.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Some Key terms before moving forward:&lt;/p&gt;&lt;h6&gt;Net activation&lt;/h6&gt;&lt;p&gt;The sum of all inputs multiplied by their weights plus the bias.&lt;/p&gt;&lt;h6&gt;Activation function&lt;/h6&gt;&lt;p&gt;Function applied to the “Net activation” transforming it into the output.&lt;/p&gt;&lt;h6&gt;Convergence&lt;/h6&gt;&lt;p&gt;The model learns the loss is minimized.&lt;/p&gt;&lt;h6&gt;Epoch&lt;/h6&gt;&lt;p&gt;Going through all the training sample i.e. number of rounds.&lt;/p&gt;&lt;h6&gt;Forward pass&lt;/h6&gt;&lt;p&gt;Getting the model output a feed forward network has connections in one direction.&lt;/p&gt;&lt;h6&gt;Learning rate&lt;/h6&gt;&lt;p&gt;The rate at which the model changes.&lt;/p&gt;&lt;br&gt;&lt;h5&gt;References&lt;/h5&gt;&lt;ol&gt;&lt;li&gt;Chapter 19 &lt;span style="color: #000000"&gt;&lt;span style="font-family: Open Sans;"&gt;&lt;span style="font-size: 0.875rem;"&gt;Artificial intelligence a modern approach&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="font-family: Open Sans;"&gt;&lt;span style="font-size: 0.875rem;"&gt;by Stuart J. Russell and Peter Norvig,&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;UC Berkeley CS188 Intro to AI&amp;nbsp;&lt;a href="http://ai.berkeley.edu/home.html"&gt;http://ai.berkeley.edu/home.html&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</TEXT><TYPE
   value="H"/></BODY><DATES><CREATED value="2024-10-04 18:31:46 EDT"/><UPDATED value="2024-11-13 23:50:51 EST"/><START
   value=""/><END value=""/></DATES><FLAGS><ISAVAILABLE value="true"/><ISFROMCARTRIDGE value="false"/><ISFOLDER
   value="false"/><ISDESCRIBED value="false"/><ISTRACKED value="true"/><ISLESSON value="false"/><ISSEQUENTIAL
   value="false"/><ALLOWGUESTS value="true"/><ALLOWOBSERVERS value="true"/><LAUNCHINNEWWINDOW
   value="false"/><ISREVIEWABLE value="false"/><ISGROUPCONTENT value="false"/><ISSAMPLECONTENT
   value="false"/><PARTIALLYVISIBLE value="false"/><HASTHUMBNAIL value="false"/></FLAGS><CONTENTHANDLER
  value="resource/x-bb-document"/><RENDERTYPE value="REGULAR"/><FOLDERTYPE value=""/><URL value=""/><VIEWMODE
  value="TEXT_ICON_ONLY"/><OFFLINENAME value=""/><OFFLINEPATH value=""/><LINKREF value=""/><PARENTID
  value="_800526_1"/><REVIEWABLEREASON value="NONE"/><VERSION value="3"/><THUMBNAILALT value=""/><AISTATE
  value="No"/><AIACCEPTINGUSER value=""/><EXTENDEDDATA/><FILES/></CONTENT>
