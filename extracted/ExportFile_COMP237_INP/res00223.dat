<?xml version="1.0" encoding="UTF-8"?>
<CONTENT id="_800676_1"><TITLE value="Topic 6.3 Classification models evaluation"/><TITLECOLOR
  value="#000000"/><DESCRIPTION
   value=""/><BODY><TEXT>&lt;div data-layout-row="ec2f0721-eb0b-48a0-9e1c-c209ccf7e1ed"&gt;&lt;div data-layout-column="1cd579a2-d31d-4395-9158-783e8b9b45a5" data-layout-column-width="12"&gt;&lt;div data-bbid="bbml-editor-id_f87fbd8e-4851-437d-89cd-35293d2a2ea5"&gt;&lt;h4&gt;&lt;span style="color: #1c8845"&gt;Topic 6.3 Classification models evaluation&lt;/span&gt;&lt;/h4&gt;&lt;br&gt;&lt;p&gt;In classification algorithms the output of the model is usually a discrete number that reflects the&amp;nbsp;&lt;span style="color: #000000"&gt;&lt;strong&gt;predicted class,&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;this makes it possible to count the outputs and compare to the actual results and build some interesting metric to &lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;validate&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt; the model. &lt;/span&gt;&lt;/p&gt;&lt;p&gt;Watch this video and the continue reading:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;a href="https://mediasite.centennialcollege.ca/Mediasite/Play/abadaa9449254c658269b21cb5404a7f1d" data-bbtype="video" data-bbfile="{&amp;quot;src&amp;quot;:&amp;quot;https://mediasite.centennialcollege.ca/Mediasite/Play/abadaa9449254c658269b21cb5404a7f1d&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;https://mediasite.centennialcollege.ca/Mediasite/Play/abadaa9449254c658269b21cb5404a7f1d&amp;quot;}"&gt;https://mediasite.centennialcollege.ca/Mediasite/Play/abadaa9449254c658269b21cb5404a7f1d&lt;/a&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;As noted from the video, there are&lt;span style="color: #000000"&gt;&lt;strong&gt;&amp;nbsp;four&lt;/strong&gt;&lt;/span&gt; categories in which the predictions of a logistic regression model or any other classification algorithm, can fall in, the figure below illustrates these four:&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693082_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Confusion matrix&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M6_confusion.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;,&amp;quot;width&amp;quot;:999.4000244140625,&amp;quot;height&amp;quot;:363.10680474846276}"&gt;M6_confusion.png&lt;/a&gt;&lt;/p&gt;&lt;h5&gt;&lt;span style="color: #1c8845"&gt;Confusion matrix&lt;/span&gt;&lt;/h5&gt;&lt;br&gt;&lt;p&gt;The result of how&amp;nbsp;many correct and incorrect predictions were made, can be summarized using what is called a confusion matrix. A confusion matrix is just a &lt;span style="color: #000000"&gt;&lt;strong&gt;tabular representation&lt;/strong&gt;&lt;/span&gt; to state the number of TPs, TNs, FPs, and FNs.&lt;/p&gt;&lt;p&gt;Below is an interpretation of each cell:&lt;/p&gt;&lt;p&gt;Assuming we are classifying between &lt;span style="color: #000000"&gt;&lt;strong&gt;cats&lt;/strong&gt;&lt;/span&gt; and &lt;span style="color: #000000"&gt;&lt;strong&gt;dogs&lt;/strong&gt;&lt;/span&gt;.&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;True Positive(TP)&lt;/strong&gt;&lt;/span&gt; : Correct positive prediction, actually positive and prediction is also positive. For example the observation is labeled as a&lt;span style="color: #000000"&gt;&lt;strong&gt; cat&lt;/strong&gt;&lt;/span&gt; and the prediction predicated a &lt;span style="color: #000000"&gt;&lt;strong&gt;cat.&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;False positive (FP):&lt;/strong&gt;&lt;/span&gt; Incorrect positive prediction, actually negative but the prediction is positive. For example the observation is labeled as a &lt;span style="color: #000000"&gt;&lt;strong&gt;dog&lt;/strong&gt;&lt;/span&gt; and the prediction predicated a &lt;span style="color: #000000"&gt;&lt;strong&gt;cat&lt;/strong&gt;&lt;/span&gt;.&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;False Negative (FN):&lt;/strong&gt;&lt;/span&gt; Incorrect negative prediction, Actually positive and prediction is negative. For example the observation is labeled as a &lt;span style="color: #000000"&gt;&lt;strong&gt;cat&lt;/strong&gt;&lt;/span&gt; and the prediction predicated a &lt;span style="color: #000000"&gt;&lt;strong&gt;&amp;nbsp;dog&lt;/strong&gt;&lt;/span&gt;.&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;True Negative:&lt;/strong&gt;&lt;/span&gt; Correct negative prediction. Actually negative and prediction is also negative. For example the observation is labeled as a &lt;span style="color: #000000"&gt;&lt;strong&gt;dog&lt;/strong&gt;&lt;/span&gt; and the prediction predicated a &lt;span style="color: #000000"&gt;&lt;strong&gt;dog&lt;/strong&gt;&lt;/span&gt;.&lt;/p&gt;&lt;p&gt;From the confusion matrix we can build some interesting metrics as follows:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt;Accuracy of a model = (TP+TN)/(TP+FP+TN+FN)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt;Precision of a model = TP / (TP+ FP)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt;Recall of a model&amp;nbsp;&amp;nbsp;= TP/ (TP+FN)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: left;"&gt;We can also calculate the following stats off a confusion matrix:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt;The total number of actual positive =&amp;nbsp;TP+FN&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt;The total number of actual negative =&amp;nbsp;TN+FP&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt;The total number of correct predictions =&amp;nbsp;TP+TN&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #1c8845"&gt;&lt;span style="font-size: 1.125rem;"&gt;The total number of incorrect predictions =&amp;nbsp;FP+FN&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h5&gt;&lt;span style="color: #1c8845"&gt;&lt;strong&gt;Receiver Operating Characteristic&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #1c8845"&gt;&amp;nbsp;(&lt;/span&gt;&lt;span style="color: #1c8845"&gt;&lt;strong&gt;ROC&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #1c8845"&gt;) curve &lt;/span&gt;&lt;/h5&gt;&lt;br&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;We can&lt;/span&gt; now understand the terms that are the constituents of a ROC curve.&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;Sensitivity or Re-call&lt;/strong&gt;&lt;/span&gt; (True Positive Rate): This is&amp;nbsp;the proportion of the positive outcomes that are identified as such (as positives) by the model:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #1c8845"&gt;Sensitivity = TP/(TP+FN)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;Specificity (True Negative Rate):&lt;/strong&gt;&lt;/span&gt; This&amp;nbsp;is the proportion of the negative outcomes that are identified as such (as negatives) by the model:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #1c8845"&gt;Specificity = TN/(TN+FP)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;An ROC curve has the following important properties:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Any increase in Sensitivity will decrease the Specificity&lt;/li&gt;&lt;li&gt;The closer the curve is to the left and upper border of the quadrant, the better the model prediction&lt;/li&gt;&lt;li&gt;The closer the curve is to the diagonal line, the worse the model prediction is&lt;/li&gt;&lt;li&gt;The larger the area under the curve, the better the prediction&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The figure below illustrates an ROC:&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693083_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;ROC&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M6_ROC.jpg&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/jpeg&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;}"&gt;M6_ROC.jpg&lt;/a&gt;&lt;/p&gt;&lt;p&gt;If the ROC curve lies above the diagonal line, then the model is considered a better predictor than a &lt;span style="color: #000000"&gt;random guess&lt;/span&gt; (represented by a diagonal line). An ROC curve lying below the diagonal line indicates that the model is a worse predictor compared to a &lt;span style="color: #000000"&gt;random guess&lt;/span&gt;.&lt;/p&gt;&lt;br&gt;&lt;h5&gt;References&lt;/h5&gt;&lt;ol&gt;&lt;li&gt;Chapter 6 &lt;span style="font-family: Open Sans;"&gt;&lt;span style="font-size: 0.875rem;"&gt;Python: Advanced Predictive Analytics, by Joseph Babcock and Ashish Kumar.&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</TEXT><TYPE
   value="H"/></BODY><DATES><CREATED value="2024-10-04 18:31:45 EDT"/><UPDATED value="2024-11-13 23:22:23 EST"/><START
   value=""/><END value=""/></DATES><FLAGS><ISAVAILABLE value="true"/><ISFROMCARTRIDGE value="false"/><ISFOLDER
   value="false"/><ISDESCRIBED value="false"/><ISTRACKED value="true"/><ISLESSON value="false"/><ISSEQUENTIAL
   value="false"/><ALLOWGUESTS value="true"/><ALLOWOBSERVERS value="true"/><LAUNCHINNEWWINDOW
   value="false"/><ISREVIEWABLE value="false"/><ISGROUPCONTENT value="false"/><ISSAMPLECONTENT
   value="false"/><PARTIALLYVISIBLE value="false"/><HASTHUMBNAIL value="false"/></FLAGS><CONTENTHANDLER
  value="resource/x-bb-document"/><RENDERTYPE value="REGULAR"/><FOLDERTYPE value=""/><URL value=""/><VIEWMODE
  value="TEXT_ICON_ONLY"/><OFFLINENAME value=""/><OFFLINEPATH value=""/><LINKREF value=""/><PARENTID
  value="_800518_1"/><REVIEWABLEREASON value="NONE"/><VERSION value="3"/><THUMBNAILALT value=""/><AISTATE
  value="No"/><AIACCEPTINGUSER value=""/><EXTENDEDDATA/><FILES/></CONTENT>
