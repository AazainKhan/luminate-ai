<?xml version="1.0" encoding="UTF-8"?>
<CONTENT id="_800677_1"><TITLE value="Topic 9.3: Feedforward Networks"/><TITLECOLOR value="#000000"/><DESCRIPTION
   value=""/><BODY><TEXT>&lt;div data-layout-row="49c3bb1a-bc86-406a-913a-c26ca6a1c598"&gt;&lt;div data-layout-column="36a75e2a-4a1c-4190-9c6f-14092565eb31" data-layout-column-width="12"&gt;&lt;div data-bbid="bbml-editor-id_577dad1a-92b3-4c4d-9263-02859096493c"&gt;&lt;h4&gt;Topic 9.3: Feedforward Networks&lt;/h4&gt;&lt;br&gt;&lt;h5&gt;&lt;span style="color: #1c8845"&gt;Feedforward networks&lt;/span&gt;&lt;/h5&gt;&lt;br&gt;&lt;p&gt;A feed-forward network has connections only in &lt;span style="color: #000000"&gt;&lt;strong&gt;one direction&lt;/strong&gt;&lt;/span&gt;—that is, it forms a directed &lt;span style="color: #000000"&gt;&lt;strong&gt;acyclic graph&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Every node receives input from “upstream” nodes and delivers output to “downstream” nodes; there&lt;span style="color: #000000"&gt;&lt;strong&gt; are no loops&lt;/strong&gt;&lt;/span&gt;.&lt;/p&gt;&lt;p&gt;Watch this video and continue reading:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;a href="https://mediasite.centennialcollege.ca/Mediasite/Play/062ac016c0ba45e089bfbf5f9355b07f1d" data-bbtype="video" data-bbfile="{&amp;quot;src&amp;quot;:&amp;quot;https://mediasite.centennialcollege.ca/Mediasite/Play/062ac016c0ba45e089bfbf5f9355b07f1d&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;https://mediasite.centennialcollege.ca/Mediasite/Play/062ac016c0ba45e089bfbf5f9355b07f1d&amp;quot;}"&gt;https://mediasite.centennialcollege.ca/Mediasite/Play/062ac016c0ba45e089bfbf5f9355b07f1d&lt;/a&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;As noted from the video each unit computes a function of its inputs and passes the results to its successor. The number of hidden layers can be set to more than one, usually three or four, if the number of hidden layers goes beyond then the network would be consider as a deep learning network.&lt;/p&gt;&lt;p&gt;The number of nodes in each hidden layer is also configurable and does not have to be equal.&lt;/p&gt;&lt;p&gt;Boolean circuits that implement Boolean functions are an example of feedforward networks.&lt;/p&gt;&lt;p&gt;In neural networks, &lt;span style="color: #000000"&gt;&lt;strong&gt;input values&lt;/strong&gt;&lt;/span&gt; are usually &lt;span style="color: #000000"&gt;&lt;strong&gt;continuous&lt;/strong&gt;&lt;/span&gt;, and nodes (units) take &lt;span style="color: #000000"&gt;&lt;strong&gt;continuous input&lt;/strong&gt;&lt;/span&gt; and produce &lt;span style="color: #000000"&gt;&lt;strong&gt;continuous outputs&lt;/strong&gt;&lt;/span&gt;.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The below figures illustrate some configurations of different feedforward networks:&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Single layer&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693159_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Single layer network&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M9_layer1.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;,&amp;quot;width&amp;quot;:737,&amp;quot;height&amp;quot;:348.94380853277835}"&gt;M9_layer1.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Two hidden layers&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693160_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Two hidden layer ANN&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M9_layer2.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;,&amp;quot;width&amp;quot;:794,&amp;quot;height&amp;quot;:283.1691995947315}"&gt;M9_layer2.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Three hidden layers&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693161_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Three hidden layer ANN&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M9_layer3.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;,&amp;quot;width&amp;quot;:850,&amp;quot;height&amp;quot;:232.24043715846994}"&gt;M9_layer3.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Unit (node):&lt;/strong&gt; The basic unit of computation&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Layer:&lt;/strong&gt; A collection of nodes of the same type and index (i.e. input, hidden, outer layer)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Connection:&lt;/strong&gt; A weighted relationship between a node of one layer to the node of another layer&lt;/p&gt;&lt;p&gt;&lt;strong&gt;W:&lt;/strong&gt; The weight of a connection&lt;/p&gt;&lt;p&gt;&lt;strong&gt;I:&lt;/strong&gt; Input node (the neural network input)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;H:&lt;/strong&gt; Hidden node (a weighted sum of input layers or previous hidden layers)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;HA:&lt;/strong&gt; Hidden node activated (the value of the hidden node passed to a predefined function)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;O:&lt;/strong&gt; Output node (A weighted sum of the last hidden layer)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;OA:&lt;/strong&gt; Output node activated&lt;/p&gt;&lt;p&gt;&lt;strong&gt;B:&lt;/strong&gt; Bias node (typically set equal to 1.0)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;e:&lt;/strong&gt; Total difference between the output of the network and the actual value(s)&lt;/p&gt;&lt;h5&gt;Steps for setting up Feedforward network&lt;/h5&gt;&lt;h6&gt;Step 1: Initialization&lt;/h6&gt;&lt;p&gt;The first step after designing(Setting the number of hidden layers and number of units per layer) a neural network is initialization:&lt;/p&gt;&lt;p&gt;Initialize all weights W&lt;sub&gt;1&lt;/sub&gt; through W&lt;sub&gt;12&lt;/sub&gt; with a random number from a normal distribution, i.e.&amp;nbsp;~N(0, 1).&lt;/p&gt;&lt;p&gt;Set all bias nodes B&lt;sub&gt;1&lt;/sub&gt; = B&lt;sub&gt;2&lt;/sub&gt; = 1.0.&lt;/p&gt;&lt;h6&gt;Step 2: Feed-Forward&lt;/h6&gt;&lt;p&gt;Calculate and move forward in the network all the values for the hidden layers and output layers.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Set the values of all input nodes.&lt;/li&gt;&lt;li&gt;Calculate hidden node values.&lt;/li&gt;&lt;li&gt;Select an &lt;span style="color: #000000"&gt;&lt;strong&gt;activation function&lt;/strong&gt;&lt;/span&gt; for the hidden layer; for example, the Sigmoid function or RelU..etc&lt;/li&gt;&lt;li&gt;Calculate hidden node activation values.&lt;/li&gt;&lt;/ul&gt;&lt;h6&gt;Step 3: Backpropagation&lt;/h6&gt;&lt;p&gt;This is the step where the magic happens. The goal of this step is to&lt;span style="color: #000000"&gt;&lt;strong&gt; incrementally adjust the weights &amp;amp; biases&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&amp;nbsp;&lt;/span&gt;in order for the network to produce values as close as possible to the expected values from the training data.&lt;/p&gt;&lt;p&gt;Backpropagation can adjust the network weights using the &lt;span style="color: #000000"&gt;&lt;strong&gt;stochastic gradient decent optimization method&lt;/strong&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Watch this video where you can visualize and get more information about feedforward neural networks:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;a href="https://www.youtube.com/embed/aircAruvnKk?feature=oembed&amp;amp;wmode=opaque&amp;amp;rel=0" data-bbtype="video" data-bbfile="{&amp;quot;src&amp;quot;:&amp;quot;https://www.youtube.com/embed/aircAruvnKk?feature=oembed&amp;amp;wmode=opaque&amp;amp;rel=0&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;https://www.youtube.com/embed/aircAruvnKk?feature=oembed&amp;amp;wmode=opaque&amp;amp;rel=0&amp;quot;}"&gt;https://www.youtube.com/embed/aircAruvnKk?feature=oembed&amp;amp;wmode=opaque&amp;amp;rel=0&lt;/a&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;h5&gt;References&lt;/h5&gt;&lt;p&gt;1- Chapter 21 Artificial intelligence a modern approach by Stuart J. Russell and Peter Norvig.&lt;/p&gt;&lt;p&gt;2- FA18 CS188 Lecture 22 -- Optimization and Neural Nets&lt;/p&gt;&lt;p&gt;3- Chapter 19&amp;nbsp;&lt;a href="https://learning.oreilly.com/library/view/artificial-intelligence-with/9781786464392/"&gt;Artificial Intelligence with Python second edition&lt;/a&gt;&amp;nbsp;by Prateek Joshi&amp;nbsp;&amp;nbsp;by Prateek Joshi&lt;/p&gt;&lt;p&gt;4-&amp;nbsp;&lt;a href="https://dzone.com/articles/the-very-basic-introduction-to-feed-forward-neural"&gt;https://dzone.com/articles/the-very-basic-introduction-to-feed-forward-neural&lt;/a&gt;&lt;/p&gt;&lt;p&gt;5-&amp;nbsp;&lt;a href="https://en.wikipedia.org/wiki/Feedforward_neural_network"&gt;https://en.wikipedia.org/wiki/Feedforward_neural_network&lt;/a&gt;&lt;/p&gt;&lt;h5&gt;&lt;span style="color: #046ef6"&gt;Activity: Check this demo&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;Click &lt;a href="http://playground.tensorflow.org/#activation=relu&amp;amp;regularization=L1&amp;amp;batchSize=10&amp;amp;dataset=spiral&amp;amp;regDataset=reg-plane&amp;amp;learningRate=0.1&amp;amp;regularizationRate=0.001&amp;amp;noise=0&amp;amp;networkShape=4,2,2&amp;amp;seed=0.69935&amp;amp;showTestData=false&amp;amp;discretize=true&amp;amp;percTrainData=70&amp;amp;x=true&amp;amp;y=true&amp;amp;xTimesY=false&amp;amp;xSquared=false&amp;amp;ySquared=false&amp;amp;cosX=false&amp;amp;sinX=false&amp;amp;cosY=false&amp;amp;sinY=false&amp;amp;collectStats=false&amp;amp;problem=classification&amp;amp;initZero=false&amp;amp;hideText=false"&gt;Neural network playground from tensor flow&lt;/a&gt; to start the neural network demo:&lt;/p&gt;&lt;p&gt;Play around with:&lt;/p&gt;&lt;p&gt;1- The number of hidden layers&amp;nbsp;&lt;/p&gt;&lt;p&gt;2- The learning rate&lt;/p&gt;&lt;p&gt;&lt;a href="http://playground.tensorflow.org/"&gt;http://playground.tensorflow.org/#activation=relu&amp;amp;regularization=L1&amp;amp;batchSize=10&amp;amp;dataset=spiral&amp;amp;regDataset=reg-plane&amp;amp;learningRate=0.1&amp;amp;regularizationRate=0.001&amp;amp;noise=0&amp;amp;networkShape=4,2,2&amp;amp;seed=0.69935&amp;amp;showTestData=false&amp;amp;discretize=true&amp;amp;percTrainData=70&amp;amp;x=true&amp;amp;y=true&amp;amp;xTimesY=false&amp;amp;xSquared=false&amp;amp;ySquared=false&amp;amp;cosX=false&amp;amp;sinX=false&amp;amp;cosY=false&amp;amp;sinY=false&amp;amp;collectStats=false&amp;amp;problem=classification&amp;amp;initZero=false&amp;amp;hideText=false&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</TEXT><TYPE
   value="H"/></BODY><DATES><CREATED value="2024-10-04 18:31:47 EDT"/><UPDATED value="2024-11-13 23:59:39 EST"/><START
   value=""/><END value=""/></DATES><FLAGS><ISAVAILABLE value="true"/><ISFROMCARTRIDGE value="false"/><ISFOLDER
   value="false"/><ISDESCRIBED value="false"/><ISTRACKED value="true"/><ISLESSON value="false"/><ISSEQUENTIAL
   value="false"/><ALLOWGUESTS value="true"/><ALLOWOBSERVERS value="true"/><LAUNCHINNEWWINDOW
   value="false"/><ISREVIEWABLE value="false"/><ISGROUPCONTENT value="false"/><ISSAMPLECONTENT
   value="false"/><PARTIALLYVISIBLE value="false"/><HASTHUMBNAIL value="false"/></FLAGS><CONTENTHANDLER
  value="resource/x-bb-document"/><RENDERTYPE value="REGULAR"/><FOLDERTYPE value=""/><URL value=""/><VIEWMODE
  value="TEXT_ICON_ONLY"/><OFFLINENAME value=""/><OFFLINEPATH value=""/><LINKREF value=""/><PARENTID
  value="_800532_1"/><REVIEWABLEREASON value="NONE"/><VERSION value="3"/><THUMBNAILALT value=""/><AISTATE
  value="No"/><AIACCEPTINGUSER value=""/><EXTENDEDDATA/><FILES/></CONTENT>
