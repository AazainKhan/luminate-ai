<?xml version="1.0" encoding="UTF-8"?>
<CONTENT id="_800691_1"><TITLE value="Topic 8.4: Gradient Descent"/><TITLECOLOR value="#000000"/><DESCRIPTION
   value=""/><BODY><TEXT>&lt;div data-layout-row="d78efd51-a13b-4ede-b01b-8b6bdc04ddf8"&gt;&lt;div data-layout-column="1ee8eaaf-b713-4ef1-991e-ed34c2cd5512" data-layout-column-width="12"&gt;&lt;div data-bbid="bbml-editor-id_1f148a8d-5492-493f-aeb0-63a25f372463"&gt;&lt;h4&gt;Topic 8.4: Gradient Descent&lt;/h4&gt;&lt;br&gt;&lt;h5&gt;&lt;span style="color: #1c8845"&gt;Gradient Descent&amp;nbsp;&lt;/span&gt;&lt;/h5&gt;&lt;br&gt;&lt;p&gt;To go beyond linear models and perceptron's, we will need to face the fact that the equations defining&lt;span style="color: #000000"&gt;&lt;strong&gt; minimum loss&lt;/strong&gt;&lt;/span&gt;&amp;nbsp;will often have no closed-form solution. Instead, we will face a&lt;span style="color: #000000"&gt;&lt;strong&gt; general optimization&lt;/strong&gt;&lt;/span&gt; search problem in a &lt;span style="color: #000000"&gt;&lt;strong&gt;continuous weight space&lt;/strong&gt;&lt;/span&gt;. This has led to the development of a more general optimization rule named &lt;span style="color: #000000"&gt;&lt;strong&gt;gradient descent.&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Watch this video then continue reading:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;a href="https://mediasite.centennialcollege.ca/Mediasite/Play/036182f9d29941c99a9434f4212ded081d" data-bbtype="video" data-bbfile="{&amp;quot;src&amp;quot;:&amp;quot;https://mediasite.centennialcollege.ca/Mediasite/Play/036182f9d29941c99a9434f4212ded081d&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;https://mediasite.centennialcollege.ca/Mediasite/Play/036182f9d29941c99a9434f4212ded081d&amp;quot;}"&gt;https://mediasite.centennialcollege.ca/Mediasite/Play/036182f9d29941c99a9434f4212ded081d&lt;/a&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;h5&gt;&lt;span style="color: #1c8845"&gt;Main Concept&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;The univariate linear model had a nice property that it is easy to find an optimal solution where the partial derivatives are zero.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;This is not always the case The loss function might not be a smooth convex as we saw in logistic regression, recall the below figure.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693075_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;loss function linear versus logistic&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M6_linear_logistic.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;,&amp;quot;width&amp;quot;:890.800048828125,&amp;quot;height&amp;quot;:333.95978486427094}"&gt;M6_linear_logistic.png&lt;/a&gt;&lt;span style="color: #000000"&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Therefore the a general optimization method&amp;nbsp;or algorithm called &lt;span style="color: #000000"&gt;&lt;strong&gt;"Gradient Descent"&lt;/strong&gt;&lt;/span&gt; for minimizing the loss that does not depend on solving to find the the zeros of derivatives has been introduced. This method can be used for any machine learning algorithm and the main flow is as follows:&lt;/p&gt;&lt;p&gt;We can generalize the approach as follows:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;w ← any point in the parameter space&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;loop until convergence do&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;for each w&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt; in w do&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt; ← w&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt; − α ( ∂ Loss (w) /∂wi)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Taking the partial derivatives of each weight item, with respect to the total Loss function, and fixing the rest of the weight space, will give us a direction to move. Have a look at the below figure:&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693138_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;boy finding his way using gradient&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M8_Gradient_with_Change.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;,&amp;quot;width&amp;quot;:517.2875366210938,&amp;quot;height&amp;quot;:425.8893787400892}"&gt;M8_Gradient_with_Change.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;We intend to minimize the error function. From math, we know that the minimum of a function must lie at a point where the gradient (rate of change) is zero. Gradient descent algorithm finds a &lt;span style="color: #000000"&gt;&lt;strong&gt;local minimum&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;of a function by taking &lt;span style="color: #000000"&gt;&lt;strong&gt;steps&lt;/strong&gt;&lt;/span&gt; proportional to the negative of the gradient of the function at the current point.&lt;/p&gt;&lt;p&gt;The size of the step is important: if the slope is large, then take a large step. If the size is small, then take a baby step because as the slope approaches zero, we approach the minimum (i.e. convergence). Have a look at the below figure which illustrates the size of the step:&lt;/p&gt;&lt;p&gt;&lt;a href="@X@EmbeddedFile.requestUrlStub@X@bbcswebdav/xid-1693139_1" data-bbtype="attachment" data-bbfile="{&amp;quot;alternativeText&amp;quot;:&amp;quot;Step size&amp;quot;,&amp;quot;linkName&amp;quot;:&amp;quot;M8_Gradient_steps.png&amp;quot;,&amp;quot;mimeType&amp;quot;:&amp;quot;image/png&amp;quot;,&amp;quot;render&amp;quot;:&amp;quot;inline&amp;quot;,&amp;quot;width&amp;quot;:912.4000244140625,&amp;quot;height&amp;quot;:326.5352961650789}"&gt;M8_Gradient_steps.png&lt;/a&gt;&lt;/p&gt;&lt;p&gt;What is important is to set the right learning rate, usually between 0.1 and 1, as the step size is calculated as follows:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #1c8845"&gt;&lt;strong&gt;Step size (on the x-axis) = slope * learning rate&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;h6&gt;To see a live example, watch the following video:&lt;/h6&gt;&lt;p style="text-align: center;"&gt;&lt;a href="https://www.youtube.com/embed/sDv4f4s2SB8?feature=oembed&amp;amp;wmode=opaque&amp;amp;rel=0" data-bbtype="video" data-bbfile="{&amp;quot;src&amp;quot;:&amp;quot;https://www.youtube.com/embed/sDv4f4s2SB8?feature=oembed&amp;amp;wmode=opaque&amp;amp;rel=0&amp;quot;,&amp;quot;alt&amp;quot;:&amp;quot;https://www.youtube.com/embed/sDv4f4s2SB8?feature=oembed&amp;amp;wmode=opaque&amp;amp;rel=0&amp;quot;}"&gt;https://www.youtube.com/embed/sDv4f4s2SB8?feature=oembed&amp;amp;wmode=opaque&amp;amp;rel=0&lt;/a&gt;&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;h5&gt;&lt;span style="color: #1c8845"&gt;&lt;strong&gt;Mathematical derivation&lt;/strong&gt;&lt;/span&gt;&lt;/h5&gt;&lt;br&gt;&lt;p&gt;&lt;strong&gt;Univariate regression:&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The loss function is a quadratic function, so the partial derivative will be a linear function.&lt;/p&gt;&lt;p&gt;The mathematical calculus required is the following three rules:&lt;/p&gt;&lt;p style="text-align: center;"&gt;∂/∂x (x^2) = 2x&lt;/p&gt;&lt;p style="text-align: center;"&gt;∂/∂x (x) = 1&lt;/p&gt;&lt;p style="text-align: center;"&gt;Chain rule&lt;/p&gt;&lt;p style="text-align: center;"&gt;∂/∂x(g(f(x)) =&amp;nbsp;g’(f(x))* ∂/∂x (f(x))&lt;/p&gt;&lt;p&gt;The general rule is:&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;w&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt; ← w&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt; − α ( ∂ Loss (w) /∂w&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;span style="font-size: 1.125rem;"&gt;)&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;eq1&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Let us take only one training example, (x, y) note: L = Loss(w)&lt;/p&gt;&lt;p style="text-align: center;"&gt;∂L /∂wi = ∂/ ∂w&lt;sub&gt;i&amp;nbsp;&lt;/sub&gt;&amp;nbsp;(y − hw(x)) 2&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Apply the chain rule&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Take the square out and multiply with the function in the brackets:&lt;/p&gt;&lt;p style="text-align: center;"&gt;=&amp;nbsp;2(y −( w1x + w0)) × ∂(y − (w1x + w0))/ ∂wi&lt;/p&gt;&lt;p&gt;Now take partial derivatives for each of the weights, i.e fix everything else :&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;First for w0&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;∂ L/∂w&lt;sub&gt;0&lt;/sub&gt; = 2 (y −( h(x)) × ∂ (y − (w&lt;sub&gt;1&lt;/sub&gt;x + w&lt;sub&gt;0&lt;/sub&gt;))/ ∂w&lt;sub&gt;0&lt;/sub&gt;&lt;/p&gt;&lt;p&gt;∂ L/∂w&lt;sub&gt;0&lt;/sub&gt; = 2 (y −( h(x)) × ∂y/ ∂w&lt;sub&gt;0&lt;/sub&gt;&amp;nbsp;&amp;nbsp;− ∂(w1x + w&lt;sub&gt;0&lt;/sub&gt;))/ ∂w&lt;sub&gt;0&lt;/sub&gt;&lt;/p&gt;&lt;p&gt;∂ L/∂w&lt;sub&gt;0&lt;/sub&gt; = 2 (y −( h(x)) × −( ∂(w&lt;sub&gt;1&lt;/sub&gt;x) / ∂w&lt;sub&gt;0&lt;/sub&gt;+ ∂ w&lt;sub&gt;0&lt;/sub&gt;/ ∂w&lt;sub&gt;0&lt;/sub&gt;)&lt;/p&gt;&lt;p&gt;∂ L/∂w&lt;sub&gt;0&lt;/sub&gt; = 2 (y −( h(x)) × −( 0+ 1)&lt;/p&gt;&lt;p&gt;∂ L/∂w&lt;sub&gt;0 &lt;/sub&gt;= -2 (y −( h(x))&lt;/p&gt;&lt;p&gt;As L needs to head towards&amp;nbsp;zero we can get rid of the -2&lt;/p&gt;&lt;p&gt;∂ L/∂w&lt;sub&gt;0 &lt;/sub&gt;= -2 (y −( h(x)) = 0&lt;/p&gt;&lt;p&gt;∂ L/∂w&lt;sub&gt;0&lt;/sub&gt; = - (y −( h(x)) = 0&lt;/p&gt;&lt;p&gt;Thus substituting in eq1 would show the following:&lt;/p&gt;&lt;p&gt;w&lt;sub&gt;0&lt;/sub&gt; ← w&lt;sub&gt;0&lt;/sub&gt;− α (- (y −( h(x)) )&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;eq1&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;w&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt; ← w&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt;+ α (y −( h(x) )&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;&lt;strong&gt;Second for w1&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;∂ L/∂w&lt;sub&gt;1&lt;/sub&gt; = 2 (y −( h(x)) × ∂ (y − (w&lt;sub&gt;1&lt;/sub&gt;x + w&lt;sub&gt;0&lt;/sub&gt;))/ ∂w&lt;sub&gt;1&lt;/sub&gt;&lt;/p&gt;&lt;p&gt;∂ L/∂w&lt;sub&gt;1&lt;/sub&gt; = 2 (y −( h(x)) × ∂y/ ∂w&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;&amp;nbsp;− ∂(w&lt;sub&gt;1&lt;/sub&gt;x + w&lt;sub&gt;0&lt;/sub&gt;))/ ∂w&lt;sub&gt;1&lt;/sub&gt;&lt;/p&gt;&lt;p&gt;∂ L/∂w&lt;sub&gt;1&lt;/sub&gt; = 2 (y −( h(x)) × −( (∂(w&lt;sub&gt;1&lt;/sub&gt;x) / ∂w&lt;sub&gt;1 &lt;/sub&gt;)*(∂(w&lt;sub&gt;1&lt;/sub&gt;w&lt;sub&gt;1&lt;/sub&gt;) / ∂w&lt;sub&gt;1&lt;/sub&gt; ) + ∂ w&lt;sub&gt;0&lt;/sub&gt;/ ∂w&lt;sub&gt;1&lt;/sub&gt;)&lt;/p&gt;&lt;p&gt;∂ L/∂w&lt;sub&gt;1&lt;/sub&gt; = 2 (y −( h(x)) × −( (x*1)+ 0)&lt;/p&gt;&lt;p&gt;∂ L/∂w&lt;sub&gt;1&lt;/sub&gt; = -2 (y −( h(x)) × - (x+0))&lt;/p&gt;&lt;p&gt;As L needs to equal zero we can get rid of the -2 &amp;amp; multiply by&amp;nbsp;-x&lt;/p&gt;&lt;p&gt;∂ L/∂w&lt;sub&gt;1&lt;/sub&gt; =&amp;nbsp;(y −( h(x)) × - (x)) = 0&lt;/p&gt;&lt;p&gt;&lt;span style="color: #000000"&gt;∂ L/∂w&lt;/span&gt;&lt;span style="color: #000000"&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/span&gt;&lt;span style="color: #000000"&gt; = - (y −( h(x)) x = 0&lt;/span&gt;&lt;/p&gt;&lt;h5&gt;&lt;span style="color: #1c8845"&gt;Batch Gradient Descent&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;Goes over all the training, Convergence to the unique global minimum is guaranteed (as long as we pick αsmall enough) but &lt;strong&gt;may be very slow&lt;/strong&gt;: we have to cycle through all the training data for every step, and there may be many steps.&lt;/p&gt;&lt;p&gt;For &lt;em&gt;N&lt;/em&gt; training examples, we want to minimize the sum of the individual losses for each example. The derivative of a&lt;span style="color: #000000"&gt;&lt;strong&gt; sum is the sum of the derivatives&lt;/strong&gt;&lt;/span&gt;, so we have:&lt;/p&gt;&lt;p style="text-align: center;"&gt;w&lt;sub&gt;0&lt;/sub&gt; ← w&lt;sub&gt;0&lt;/sub&gt; + α ∑(y&lt;sub&gt;j&lt;/sub&gt; − hw(x&lt;sub&gt;j&lt;/sub&gt;)) ;&lt;/p&gt;&lt;p style="text-align: center;"&gt;w&lt;sub&gt;1&lt;/sub&gt; ← w&lt;sub&gt;1&lt;/sub&gt; + α ∑ (y&lt;sub&gt;j&lt;/sub&gt; − hw(x&lt;sub&gt;j&lt;/sub&gt;))*x&lt;sub&gt;j&lt;/sub&gt;&lt;/p&gt;&lt;h5&gt;&lt;span style="color: #1c8845"&gt;Mini-batch gradient descent (random)&lt;/span&gt;&lt;/h5&gt;&lt;br&gt;&lt;p&gt;It randomly selects a small number of training examples (mini-batch) &lt;em&gt;m&lt;/em&gt; out of &lt;em&gt;N&lt;/em&gt; at each step. Used in:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;online setting, where new data are coming in one at a time.&lt;/li&gt;&lt;li&gt;offline setting, where we cycle through the same data as many times as is necessary, taking a step after considering each batch.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;It is&amp;nbsp;&lt;span style="color: #000000"&gt;&lt;strong&gt;faster&lt;/strong&gt;&lt;/span&gt; than batch gradient descent (all training examples). With a fixed learning rate &lt;em&gt;α&lt;/em&gt;, however, it &lt;span style="color: #000000"&gt;&lt;strong&gt;does not&amp;nbsp;&lt;/strong&gt;&lt;/span&gt;guarantee convergence. Mini-batch can oscillate around the minimum without settling down.&lt;/p&gt;&lt;p&gt;Applied to &lt;strong&gt;neural networks&lt;/strong&gt;. Even when the surface is not a convex the approach has proven effective in finding good local minima close to global minimum.&lt;/p&gt;&lt;br&gt;&lt;h5&gt;References&lt;/h5&gt;&lt;ol&gt;&lt;li&gt;Chapter 19 &lt;span style="color: #000000"&gt;&lt;span style="font-family: Open Sans;"&gt;&lt;span style="font-size: 0.875rem;"&gt;Artificial intelligence a modern approach&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="font-family: Open Sans;"&gt;&lt;span style="font-size: 0.875rem;"&gt;by Stuart J. Russell and Peter Norvig,&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;UC Berkeley CS188 Intro to AI&amp;nbsp;&lt;a href="http://ai.berkeley.edu/home.html"&gt;http://ai.berkeley.edu/home.html&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=sDv4f4s2SB8"&gt;https://www.youtube.com/watch?v=sDv4f4s2SB8&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</TEXT><TYPE
   value="H"/></BODY><DATES><CREATED value="2024-10-04 18:31:46 EDT"/><UPDATED value="2024-12-20 15:46:06 EST"/><START
   value=""/><END value=""/></DATES><FLAGS><ISAVAILABLE value="true"/><ISFROMCARTRIDGE value="false"/><ISFOLDER
   value="false"/><ISDESCRIBED value="false"/><ISTRACKED value="true"/><ISLESSON value="false"/><ISSEQUENTIAL
   value="false"/><ALLOWGUESTS value="true"/><ALLOWOBSERVERS value="true"/><LAUNCHINNEWWINDOW
   value="false"/><ISREVIEWABLE value="false"/><ISGROUPCONTENT value="false"/><ISSAMPLECONTENT
   value="false"/><PARTIALLYVISIBLE value="false"/><HASTHUMBNAIL value="false"/></FLAGS><CONTENTHANDLER
  value="resource/x-bb-document"/><RENDERTYPE value="REGULAR"/><FOLDERTYPE value=""/><URL value=""/><VIEWMODE
  value="TEXT_ICON_ONLY"/><OFFLINENAME value=""/><OFFLINEPATH value=""/><LINKREF value=""/><PARENTID
  value="_800527_1"/><REVIEWABLEREASON value="NONE"/><VERSION value="3"/><THUMBNAILALT value=""/><AISTATE
  value="No"/><AIACCEPTINGUSER value=""/><EXTENDEDDATA/><FILES/></CONTENT>
